[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "imfp",
    "section": "",
    "text": "imfp, created and maintained by Promptly Technologies, is a Python package for downloading data from the International Monetary Fund’s RESTful JSON API.\n\n\nTo install the stable version of imfp from PyPi, use pip.\npip install --upgrade imfp\nTo load the library, use import:\n\nimport imfp\n\n\n\n\nThe imfp package introduces four core functions: imf_databases, imf_parameters, imf_parameter_defs, and imf_dataset. The function for downloading datasets is imf_dataset, but you will need the other functions to determine what arguments to supply to your imf_dataset function call.\n\n\nFor instance, all calls to imf_dataset require a database_id. This is because the IMF serves many different databases through its API, and the API needs to know which of these many databases you’re requesting data from.\nTo fetch a list of available databases, use:\n\n# Fetch list of available databases\ndatabases = imfp.imf_databases()\n\nSee Working with Databases for more information.\n\n\n\nRequests to fetch data from IMF databases are complicated by the fact that each database uses a different set of parameters when making a request. (At last count, there were 43 unique parameters used in making API requests from the various databases!) You also have to have the list of valid input codes for each parameter. See Working with Parameters for a more detailed explanation of parameters and input codes and how they work.\nTo obtain the full list of parameters and valid input codes for a given database, use:\n\n# Fetch list of valid parameters and input codes for commodity price database\nparams = imfp.imf_parameters(\"PCPS\")\n\nThe imf_parameters function returns a dictionary of data frames. Each dictionary key name corresponds to a parameter used in making requests from the database:\n\n# Get key names from the params object\nparams.keys()\n\ndict_keys(['freq', 'ref_area', 'commodity', 'unit_measure'])\n\n\nEach named list item is a data frame containing the valid input codes (and their descriptions) that can be used with the named parameter.\nTo access the data frame containing valid values for each parameter, subset the params dict by the parameter name:\n\n# View the data frame of valid input codes for the frequency parameter\nparams['freq']\n\n\n\n\n\n\n\n\ninput_code\ndescription\n\n\n\n\n0\nA\nAnnual\n\n\n1\nM\nMonthly\n\n\n2\nQ\nQuarterly\n\n\n\n\n\n\n\n\n\n\nTo make a request to fetch data from the IMF API, just call imfp.imf_dataset with the database ID and keyword arguments for each parameter, where the keyword argument name is the parameter name and the value is the list of codes you want.\nFor instance, on exploring the freq parameter of the Primary Commodity Price System database above, we found that the frequency can take one of three values: “A” for annual, “Q” for quarterly, and “M” for monthly. Thus, to request annual data, we can call imfp.imf_dataset with freq = [\"A\"].\nSimilarly, we might search the dataframes of valid input codes for the commodity and unit_measure parameters to find the input codes for coal and index:\n\n# Find the 'commodity' input code for coal\nparams['commodity'].loc[\n    params['commodity']['description'].str.contains(\"Coal\")\n]\n\n\n\n\n\n\n\n\ninput_code\ndescription\n\n\n\n\n14\nPCOAL\nPrimary Commodity Prices, Coal index\n\n\n15\nPCOALAU\nPrimary Commodity Prices, Coal, Australia\n\n\n16\nPCOALSA\nPrimary Commodity Prices, Coal, South Africa\n\n\n\n\n\n\n\n\n# Find the 'unit_measure' input code for index\nparams['unit_measure'].loc[\n    params['unit_measure']['description'].str.contains(\"Index\")\n]\n\n\n\n\n\n\n\n\ninput_code\ndescription\n\n\n\n\n0\nIX\nIndex\n\n\n\n\n\n\n\nFinally, we can use the information we’ve gathered to make the request to fetch the data:\n\n# Request data from the API\ndf = imfp.imf_dataset(database_id = \"PCPS\",\n         freq = [\"A\"], commodity = [\"PCOAL\", \"PCOALAU\", \"PCOALSA\"],\n         unit_measure = [\"IX\"],\n         start_year = 2000, end_year = 2015)\n\n# Display the first few entries in the retrieved data frame\ndf.head()\n\n\n\n\n\n\n\n\nfreq\nref_area\ncommodity\nunit_measure\nunit_mult\ntime_format\ntime_period\nobs_value\n\n\n\n\n0\nA\nW00\nPCOAL\nIX\n0\nP1Y\n2000\n39.3510230293202\n\n\n1\nA\nW00\nPCOAL\nIX\n0\nP1Y\n2001\n49.3378587284039\n\n\n2\nA\nW00\nPCOAL\nIX\n0\nP1Y\n2002\n39.4949091648006\n\n\n3\nA\nW00\nPCOAL\nIX\n0\nP1Y\n2003\n43.2878876950788\n\n\n4\nA\nW00\nPCOAL\nIX\n0\nP1Y\n2004\n82.9185858052862\n\n\n\n\n\n\n\nThe returned data frame has a time_format column that contains ISO 8601 duration codes. In this case, “P1Y” means “periods of 1 year.” The unit_mult column represents the power of 10 to which the value column should be raised. For instance, if value is in millions, then the unit multiplier will be 6 (meaning 10^6). If in billions, then the unit multiplier will be 9 (meaning 10^9). For more information on interpreting the returned data frame, see Understanding the Data Frame.\n\n\n\n\nNote that all columns in the returned data frame are string objects, and to plot the series we will need to convert to valid numeric or date formats:\n\n# Convert obs_value to numeric and time_period to integer year\ndf = df.astype({\"time_period\" : int, \"obs_value\" : float})\n\nThen, using seaborn with hue, we can plot different indicators in different colors:\n\nimport seaborn as sns\n\n# Plot prices of different commodities in different colors with seaborn\nsns.lineplot(data=df, x='time_period', y='obs_value', hue='commodity');\n\n\n\n\n\n\n\n\n\n\n\nWe welcome contributions to improve imfp! Here’s how you can help:\n\nIf you find a bug, please open a Github issue\nTo fix a bug:\n\nFork and clone the repository and open a terminal in the repository directory\nInstall uv with curl -LsSf https://astral.sh/uv/install.sh | sh\nInstall the dependencies with uv sync\nInstall a git hook to enforce conventional commits with curl -o- https://raw.githubusercontent.com/tapsellorg/conventional-commits-git-hook/master/scripts/install.sh | sh\nCreate a fix, commit it with an “Angular-style Conventional Commit” message, and push it to your fork\nOpen a pull request to our main branch\n\n\nNote that if you want to change and preview the documentation, you will need to install the Quarto CLI tool.\nVersion incrementing, package building, testing, changelog generation, documentation rendering, publishing to PyPI, and Github release creation is handled automatically by the GitHub Actions workflow based on the commit messages.\n\n\n\nIn line with the llms.txt standard, we have exposed the full Markdown-formatted project documentation as a single text file to make it more usable by LLM agents."
  },
  {
    "objectID": "index.html#installation",
    "href": "index.html#installation",
    "title": "imfp",
    "section": "",
    "text": "To install the stable version of imfp from PyPi, use pip.\npip install --upgrade imfp\nTo load the library, use import:\n\nimport imfp"
  },
  {
    "objectID": "index.html#workflow",
    "href": "index.html#workflow",
    "title": "imfp",
    "section": "",
    "text": "The imfp package introduces four core functions: imf_databases, imf_parameters, imf_parameter_defs, and imf_dataset. The function for downloading datasets is imf_dataset, but you will need the other functions to determine what arguments to supply to your imf_dataset function call.\n\n\nFor instance, all calls to imf_dataset require a database_id. This is because the IMF serves many different databases through its API, and the API needs to know which of these many databases you’re requesting data from.\nTo fetch a list of available databases, use:\n\n# Fetch list of available databases\ndatabases = imfp.imf_databases()\n\nSee Working with Databases for more information.\n\n\n\nRequests to fetch data from IMF databases are complicated by the fact that each database uses a different set of parameters when making a request. (At last count, there were 43 unique parameters used in making API requests from the various databases!) You also have to have the list of valid input codes for each parameter. See Working with Parameters for a more detailed explanation of parameters and input codes and how they work.\nTo obtain the full list of parameters and valid input codes for a given database, use:\n\n# Fetch list of valid parameters and input codes for commodity price database\nparams = imfp.imf_parameters(\"PCPS\")\n\nThe imf_parameters function returns a dictionary of data frames. Each dictionary key name corresponds to a parameter used in making requests from the database:\n\n# Get key names from the params object\nparams.keys()\n\ndict_keys(['freq', 'ref_area', 'commodity', 'unit_measure'])\n\n\nEach named list item is a data frame containing the valid input codes (and their descriptions) that can be used with the named parameter.\nTo access the data frame containing valid values for each parameter, subset the params dict by the parameter name:\n\n# View the data frame of valid input codes for the frequency parameter\nparams['freq']\n\n\n\n\n\n\n\n\ninput_code\ndescription\n\n\n\n\n0\nA\nAnnual\n\n\n1\nM\nMonthly\n\n\n2\nQ\nQuarterly\n\n\n\n\n\n\n\n\n\n\nTo make a request to fetch data from the IMF API, just call imfp.imf_dataset with the database ID and keyword arguments for each parameter, where the keyword argument name is the parameter name and the value is the list of codes you want.\nFor instance, on exploring the freq parameter of the Primary Commodity Price System database above, we found that the frequency can take one of three values: “A” for annual, “Q” for quarterly, and “M” for monthly. Thus, to request annual data, we can call imfp.imf_dataset with freq = [\"A\"].\nSimilarly, we might search the dataframes of valid input codes for the commodity and unit_measure parameters to find the input codes for coal and index:\n\n# Find the 'commodity' input code for coal\nparams['commodity'].loc[\n    params['commodity']['description'].str.contains(\"Coal\")\n]\n\n\n\n\n\n\n\n\ninput_code\ndescription\n\n\n\n\n14\nPCOAL\nPrimary Commodity Prices, Coal index\n\n\n15\nPCOALAU\nPrimary Commodity Prices, Coal, Australia\n\n\n16\nPCOALSA\nPrimary Commodity Prices, Coal, South Africa\n\n\n\n\n\n\n\n\n# Find the 'unit_measure' input code for index\nparams['unit_measure'].loc[\n    params['unit_measure']['description'].str.contains(\"Index\")\n]\n\n\n\n\n\n\n\n\ninput_code\ndescription\n\n\n\n\n0\nIX\nIndex\n\n\n\n\n\n\n\nFinally, we can use the information we’ve gathered to make the request to fetch the data:\n\n# Request data from the API\ndf = imfp.imf_dataset(database_id = \"PCPS\",\n         freq = [\"A\"], commodity = [\"PCOAL\", \"PCOALAU\", \"PCOALSA\"],\n         unit_measure = [\"IX\"],\n         start_year = 2000, end_year = 2015)\n\n# Display the first few entries in the retrieved data frame\ndf.head()\n\n\n\n\n\n\n\n\nfreq\nref_area\ncommodity\nunit_measure\nunit_mult\ntime_format\ntime_period\nobs_value\n\n\n\n\n0\nA\nW00\nPCOAL\nIX\n0\nP1Y\n2000\n39.3510230293202\n\n\n1\nA\nW00\nPCOAL\nIX\n0\nP1Y\n2001\n49.3378587284039\n\n\n2\nA\nW00\nPCOAL\nIX\n0\nP1Y\n2002\n39.4949091648006\n\n\n3\nA\nW00\nPCOAL\nIX\n0\nP1Y\n2003\n43.2878876950788\n\n\n4\nA\nW00\nPCOAL\nIX\n0\nP1Y\n2004\n82.9185858052862\n\n\n\n\n\n\n\nThe returned data frame has a time_format column that contains ISO 8601 duration codes. In this case, “P1Y” means “periods of 1 year.” The unit_mult column represents the power of 10 to which the value column should be raised. For instance, if value is in millions, then the unit multiplier will be 6 (meaning 10^6). If in billions, then the unit multiplier will be 9 (meaning 10^9). For more information on interpreting the returned data frame, see Understanding the Data Frame."
  },
  {
    "objectID": "index.html#working-with-the-returned-data-frame",
    "href": "index.html#working-with-the-returned-data-frame",
    "title": "imfp",
    "section": "",
    "text": "Note that all columns in the returned data frame are string objects, and to plot the series we will need to convert to valid numeric or date formats:\n\n# Convert obs_value to numeric and time_period to integer year\ndf = df.astype({\"time_period\" : int, \"obs_value\" : float})\n\nThen, using seaborn with hue, we can plot different indicators in different colors:\n\nimport seaborn as sns\n\n# Plot prices of different commodities in different colors with seaborn\nsns.lineplot(data=df, x='time_period', y='obs_value', hue='commodity');"
  },
  {
    "objectID": "index.html#contributing",
    "href": "index.html#contributing",
    "title": "imfp",
    "section": "",
    "text": "We welcome contributions to improve imfp! Here’s how you can help:\n\nIf you find a bug, please open a Github issue\nTo fix a bug:\n\nFork and clone the repository and open a terminal in the repository directory\nInstall uv with curl -LsSf https://astral.sh/uv/install.sh | sh\nInstall the dependencies with uv sync\nInstall a git hook to enforce conventional commits with curl -o- https://raw.githubusercontent.com/tapsellorg/conventional-commits-git-hook/master/scripts/install.sh | sh\nCreate a fix, commit it with an “Angular-style Conventional Commit” message, and push it to your fork\nOpen a pull request to our main branch\n\n\nNote that if you want to change and preview the documentation, you will need to install the Quarto CLI tool.\nVersion incrementing, package building, testing, changelog generation, documentation rendering, publishing to PyPI, and Github release creation is handled automatically by the GitHub Actions workflow based on the commit messages."
  },
  {
    "objectID": "index.html#working-with-llms",
    "href": "index.html#working-with-llms",
    "title": "imfp",
    "section": "",
    "text": "In line with the llms.txt standard, we have exposed the full Markdown-formatted project documentation as a single text file to make it more usable by LLM agents."
  },
  {
    "objectID": "docs/rate_limits.html",
    "href": "docs/rate_limits.html",
    "title": "Rate Limits",
    "section": "",
    "text": "The IMF API imposes very restrictive (and incompletely documented) rate limits, not only for individual users and applications, but also globally for all users of the API. Thus, at high-traffic times, you may find that your requests fail. It’s highly recommended that you set up proactive error handling, wait times, retries, and request caching to avoid hitting the API’s rate limits. The imfp library provides some tools to help you do this (with more planned for future releases).\n\n\nThe IMF API has an application-based rate limit of 50 requests per second. Each application is identified by the “user_agent” variable in the request header. By default, all imfp users share the same application name, which could lead to rate limit issues if many users are making requests simultaneously.\nThis could prove problematic if the imfp library became too popular and too many users tried to make simultaneous API requests using the default app name. By setting a custom application name, users can avoid hitting this rate limit and being blocked by the API. To solve this problem, imfp supplies the set_imf_app_name() function to set a custom application name.\nset_imf_app_name() sets the application name by changing the IMF_APP_NAME variable in the environment. If this variable doesn’t exist, set_imf_app_name() will create it. To set a custom application name, simply call the set_imf_app_name() function with your desired application name as an argument:\n\nimport imfp\n\n# Set custom app name as an environment variable\nimfp.set_imf_app_name(\"my_custom_app_name\")\n\nThe function will throw an error if the provided name is missing, NULL, NA, not a string, or longer than 255 characters. If the provided name is “imfp” (the default) or an empty string, the function will issue a warning recommending the use of a unique app name to avoid hitting rate limits.\n\n\n\nIf making multiple requests in a short period of time, you may want to increase the wait time between requests to avoid hitting the API’s rate limits. This is done with the set_imf_wait_time() function:\n\n# Increase wait time to 5 seconds\nimfp.set_imf_wait_time(5)\n\n\n\n\nimfp automatically handles rate limits with exponential backoff:\n\nWaits for specified time\nRetries the request\nIncreases wait time exponentially on subsequent failures\nStops after 3 attempts (default)\n\nYou can modify retry behavior:\n\n# Retry 4 times rather than the default 3\ndf = imfp.imf_dataset(\"IFS\", \"NGDP_D_SA_IX\", times=4)\n\n\n\n\nTo reduce API calls, you can cache frequently accessed data. For instance, in a Jupyter or Quarto notebook that you run multiple times, you can wrap each imfp function call in an if statement that checks if the returned data has already been saved to a file. If it has, it loads the data from the file. If it hasn’t, it fetches the data from the API and saves it to a file.\nNote that to run this code, you will need to install the pyarrow library, which pandas uses as its engine for reading and writing parquet files (but which is not installed with pandas or imfp by default). Use pip install pyarrow to install it.\n\nimport os\nimport pandas as pd\n\n# Fetch imf databases from file if available, else from API\ncache_path = f\"data/imf_databases.parquet\"\nif os.path.exists(cache_path):\n    databases = pd.read_parquet(cache_path)\nelse:\n    databases = imfp.imf_databases()\n    os.makedirs(\"data\", exist_ok=True)\n    databases.to_parquet(cache_path)\n\nYou can also functionalize this logic to permit reuse several times in the same script or notebook. See Jenny Xu’s excellent demo notebook for example caching functions."
  },
  {
    "objectID": "docs/rate_limits.html#api-rate-management",
    "href": "docs/rate_limits.html#api-rate-management",
    "title": "Rate Limits",
    "section": "",
    "text": "The IMF API imposes very restrictive (and incompletely documented) rate limits, not only for individual users and applications, but also globally for all users of the API. Thus, at high-traffic times, you may find that your requests fail. It’s highly recommended that you set up proactive error handling, wait times, retries, and request caching to avoid hitting the API’s rate limits. The imfp library provides some tools to help you do this (with more planned for future releases).\n\n\nThe IMF API has an application-based rate limit of 50 requests per second. Each application is identified by the “user_agent” variable in the request header. By default, all imfp users share the same application name, which could lead to rate limit issues if many users are making requests simultaneously.\nThis could prove problematic if the imfp library became too popular and too many users tried to make simultaneous API requests using the default app name. By setting a custom application name, users can avoid hitting this rate limit and being blocked by the API. To solve this problem, imfp supplies the set_imf_app_name() function to set a custom application name.\nset_imf_app_name() sets the application name by changing the IMF_APP_NAME variable in the environment. If this variable doesn’t exist, set_imf_app_name() will create it. To set a custom application name, simply call the set_imf_app_name() function with your desired application name as an argument:\n\nimport imfp\n\n# Set custom app name as an environment variable\nimfp.set_imf_app_name(\"my_custom_app_name\")\n\nThe function will throw an error if the provided name is missing, NULL, NA, not a string, or longer than 255 characters. If the provided name is “imfp” (the default) or an empty string, the function will issue a warning recommending the use of a unique app name to avoid hitting rate limits.\n\n\n\nIf making multiple requests in a short period of time, you may want to increase the wait time between requests to avoid hitting the API’s rate limits. This is done with the set_imf_wait_time() function:\n\n# Increase wait time to 5 seconds\nimfp.set_imf_wait_time(5)\n\n\n\n\nimfp automatically handles rate limits with exponential backoff:\n\nWaits for specified time\nRetries the request\nIncreases wait time exponentially on subsequent failures\nStops after 3 attempts (default)\n\nYou can modify retry behavior:\n\n# Retry 4 times rather than the default 3\ndf = imfp.imf_dataset(\"IFS\", \"NGDP_D_SA_IX\", times=4)\n\n\n\n\nTo reduce API calls, you can cache frequently accessed data. For instance, in a Jupyter or Quarto notebook that you run multiple times, you can wrap each imfp function call in an if statement that checks if the returned data has already been saved to a file. If it has, it loads the data from the file. If it hasn’t, it fetches the data from the API and saves it to a file.\nNote that to run this code, you will need to install the pyarrow library, which pandas uses as its engine for reading and writing parquet files (but which is not installed with pandas or imfp by default). Use pip install pyarrow to install it.\n\nimport os\nimport pandas as pd\n\n# Fetch imf databases from file if available, else from API\ncache_path = f\"data/imf_databases.parquet\"\nif os.path.exists(cache_path):\n    databases = pd.read_parquet(cache_path)\nelse:\n    databases = imfp.imf_databases()\n    os.makedirs(\"data\", exist_ok=True)\n    databases.to_parquet(cache_path)\n\nYou can also functionalize this logic to permit reuse several times in the same script or notebook. See Jenny Xu’s excellent demo notebook for example caching functions."
  },
  {
    "objectID": "docs/rate_limits.html#performance-tips",
    "href": "docs/rate_limits.html#performance-tips",
    "title": "Rate Limits",
    "section": "Performance Tips",
    "text": "Performance Tips\n\nFilter Early: Use parameters to limit data at the API level\nParallelize Carefully: Avoid running parallel API requests, even from multiple clients\nUse Efficient Formats: Store cached data in parquet or feather files\nValidate Data: Check for errors and empty responses"
  },
  {
    "objectID": "docs/installation.html",
    "href": "docs/installation.html",
    "title": "Installation",
    "section": "",
    "text": "To install the latest version of imfp, you will need to have Python 3.10 or later installed on your system.\nIf you don’t already have Python, we recommend installing the uv package manager and installing Python with uv python install."
  },
  {
    "objectID": "docs/installation.html#prerequisites",
    "href": "docs/installation.html#prerequisites",
    "title": "Installation",
    "section": "",
    "text": "To install the latest version of imfp, you will need to have Python 3.10 or later installed on your system.\nIf you don’t already have Python, we recommend installing the uv package manager and installing Python with uv python install."
  },
  {
    "objectID": "docs/installation.html#installation",
    "href": "docs/installation.html#installation",
    "title": "Installation",
    "section": "Installation",
    "text": "Installation\nTo install the latest stable imfp wheel from PyPi using pip:\npip install --upgrade imfp\nAlternatively, to install from the source code on Github, you can use the following command:\npip install --upgrade git+https://github.com/Promptly-Technologies-LLC/imfp.git\nYou can then import the package in your Python script:\nimport imfp"
  },
  {
    "objectID": "docs/installation.html#suggested-dependencies-for-data-analysis",
    "href": "docs/installation.html#suggested-dependencies-for-data-analysis",
    "title": "Installation",
    "section": "Suggested Dependencies for Data Analysis",
    "text": "Suggested Dependencies for Data Analysis\nimfp outputs data in a pandas data frame, so you will want to use the pandas package (which is installed with imfp) for its functions for viewing and manipulating this object type. For data visualization, we recommend installing these additional packages:\npip install -q matplotlib seaborn\nYou can then import these packages in your Python script:\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns"
  },
  {
    "objectID": "docs/installation.html#development-installation",
    "href": "docs/installation.html#development-installation",
    "title": "Installation",
    "section": "Development Installation",
    "text": "Development Installation\nTo get started with development of imfp,\n\nFork and clone the repository\nInstall uv with curl -LsSf https://astral.sh/uv/install.sh | sh\nInstall the dependencies with uv sync\nInstall a git pre-commit hook to enforce conventional commits:\ncurl -o- https://raw.githubusercontent.com/tapsellorg/conventional-commits-git-hook/master/scripts/install.sh | sh\n\nTo edit and preview the documentation, you’ll also want to install the Quarto CLI tool."
  },
  {
    "objectID": "docs/datasets.html",
    "href": "docs/datasets.html",
    "title": "Requesting Datasets",
    "section": "",
    "text": "To retrieve data from an IMF database, you’ll need the database ID and any relevant filter parameters. Here’s a basic example using the Primary Commodity Price System (PCPS) database:\n\nimport imfp\n\n# Get parameters and their valid codes\nparams = imfp.imf_parameters(\"PCPS\")\n\n# Fetch annual coal price index data\ndf = imfp.imf_dataset(\n    database_id=\"PCPS\",\n    freq=[\"A\"],  # Annual frequency\n    commodity=[\"PCOAL\"],  # Coal prices\n    unit_measure=[\"IX\"],  # Index\n    start_year=2000,\n    end_year=2015\n)\n\nThis example creates two objects we’ll use in the following sections:\n\nparams: A dictionary of parameters and their valid codes\ndf: The retrieved data frame containing our requested data"
  },
  {
    "objectID": "docs/datasets.html#making-a-request",
    "href": "docs/datasets.html#making-a-request",
    "title": "Requesting Datasets",
    "section": "",
    "text": "To retrieve data from an IMF database, you’ll need the database ID and any relevant filter parameters. Here’s a basic example using the Primary Commodity Price System (PCPS) database:\n\nimport imfp\n\n# Get parameters and their valid codes\nparams = imfp.imf_parameters(\"PCPS\")\n\n# Fetch annual coal price index data\ndf = imfp.imf_dataset(\n    database_id=\"PCPS\",\n    freq=[\"A\"],  # Annual frequency\n    commodity=[\"PCOAL\"],  # Coal prices\n    unit_measure=[\"IX\"],  # Index\n    start_year=2000,\n    end_year=2015\n)\n\nThis example creates two objects we’ll use in the following sections:\n\nparams: A dictionary of parameters and their valid codes\ndf: The retrieved data frame containing our requested data"
  },
  {
    "objectID": "docs/datasets.html#decoding-returned-data",
    "href": "docs/datasets.html#decoding-returned-data",
    "title": "Requesting Datasets",
    "section": "Decoding Returned Data",
    "text": "Decoding Returned Data\nWhen you retrieve data using imf_dataset, the returned data frame contains columns that correspond to the parameters you specified in your request. However, these columns use input codes (short identifiers) rather than human-readable descriptions. To make your data more interpretable, you can replace these codes with their corresponding text descriptions using the parameter information from imf_parameters, so that codes like “A” (Annual) or “W00” (World) become self-explanatory labels.\nFor example, suppose we want to decode the freq (frequency), ref_area (geographical area), and unit_measure (unit) columns in our dataset. We’ll merge the parameter descriptions into our data frame:\n\n# Decode frequency codes (e.g., \"A\" → \"Annual\")\ndf = df.merge(\n    # Select code-description pairs\n    params['freq'][['input_code', 'description']],\n    # Match codes in the data frame\n    left_on='freq',\n    # ...to codes in the parameter data\n    right_on='input_code',\n    # Keep all data rows\n    how='left'\n).drop(columns=['freq', 'input_code']\n).rename(columns={\"description\": \"freq\"})\n\n# Decode geographic area codes (e.g., \"W00\" → \"World\")\ndf = df.merge(\n    params['ref_area'][['input_code', 'description']],\n    left_on='ref_area',\n    right_on='input_code',\n    how='left'\n).drop(columns=['ref_area', 'input_code']\n).rename(columns={\"description\":\"ref_area\"})\n\n# Decode unit codes (e.g., \"IX\" → \"Index\")\ndf = df.merge(\n    params['unit_measure'][['input_code', 'description']],\n    left_on='unit_measure',\n    right_on='input_code',\n    how='left'\n).drop(columns=['unit_measure', 'input_code']\n).rename(columns={\"description\":\"unit_measure\"})\n\ndf.head()\n\n\n\n\n\n\n\n\ncommodity\nunit_mult\ntime_format\ntime_period\nobs_value\nfreq\nref_area\nunit_measure\n\n\n\n\n0\nPCOAL\n0\nP1Y\n2000\n39.3510230293202\nAnnual\nAll Countries, excluding the IO\nIndex\n\n\n1\nPCOAL\n0\nP1Y\n2001\n49.3378587284039\nAnnual\nAll Countries, excluding the IO\nIndex\n\n\n2\nPCOAL\n0\nP1Y\n2002\n39.4949091648006\nAnnual\nAll Countries, excluding the IO\nIndex\n\n\n3\nPCOAL\n0\nP1Y\n2003\n43.2878876950788\nAnnual\nAll Countries, excluding the IO\nIndex\n\n\n4\nPCOAL\n0\nP1Y\n2004\n82.9185858052862\nAnnual\nAll Countries, excluding the IO\nIndex\n\n\n\n\n\n\n\nAfter decoding, the data frame is much more human-interpretable. This transformation makes the data more accessible for analysis and presentation, while maintaining all the original information."
  },
  {
    "objectID": "docs/datasets.html#understanding-the-data-frame",
    "href": "docs/datasets.html#understanding-the-data-frame",
    "title": "Requesting Datasets",
    "section": "Understanding the Data Frame",
    "text": "Understanding the Data Frame\nAlso note that the returned data frame has additional mysterious-looking codes as values in some columns.\nCodes in the time_format column are ISO 8601 duration codes. In this case, “P1Y” means “periods of 1 year.” See Time Period Conversion for more information on reconciling time periods.\nThe unit_mult column represents the number of zeroes you should add to the value column. For instance, if value is in millions, then the unit multiplier will be 6. If in billions, then the unit multiplier will be 9. See Unit Multiplier Adjustment for more information on reconciling units."
  },
  {
    "objectID": "docs/databases.html",
    "href": "docs/databases.html",
    "title": "Working with Databases",
    "section": "",
    "text": "The IMF serves many different databases through its API, and the API needs to know which of these many databases you’re requesting data from. Before you can fetch any data, you’ll need to:\n\nGet a list of available databases\nFind the database ID for the data you want\n\nThen you can use that database ID to fetch the data."
  },
  {
    "objectID": "docs/databases.html#understanding-imf-databases",
    "href": "docs/databases.html#understanding-imf-databases",
    "title": "Working with Databases",
    "section": "",
    "text": "The IMF serves many different databases through its API, and the API needs to know which of these many databases you’re requesting data from. Before you can fetch any data, you’ll need to:\n\nGet a list of available databases\nFind the database ID for the data you want\n\nThen you can use that database ID to fetch the data."
  },
  {
    "objectID": "docs/databases.html#fetching-the-database-list",
    "href": "docs/databases.html#fetching-the-database-list",
    "title": "Working with Databases",
    "section": "Fetching the Database List",
    "text": "Fetching the Database List\n\nFetching an Index of Databases with the imf_databases Function\nTo obtain the list of available databases and their corresponding IDs, use imf_databases:\n\nimport imfp\n\n#Fetch the list of databases available through the IMF API\ndatabases = imfp.imf_databases()\ndatabases.head()\n\n\n\n\n\n\n\n\ndatabase_id\ndescription\n\n\n\n\n0\nBOP_2017M06\nBalance of Payments (BOP), 2017 M06\n\n\n1\nBOP_2020M3\nBalance of Payments (BOP), 2020 M03\n\n\n2\nBOP_2017M11\nBalance of Payments (BOP), 2017 M11\n\n\n3\nDOT_2020Q1\nDirection of Trade Statistics (DOTS), 2020 Q1\n\n\n4\nGFSMAB2016\nGovernment Finance Statistics Yearbook (GFSY 2...\n\n\n\n\n\n\n\nThis function returns the IMF’s listing of 259 databases available through the API. (In reality, a few of the listed databases are defunct and not actually available. The databases FAS_2015, GFS01, FM202010, APDREO202010, AFRREO202010, WHDREO202010, BOPAGG_2020, and DOT_2020Q1 were unavailable as of last check.)"
  },
  {
    "objectID": "docs/databases.html#exploring-the-database-list",
    "href": "docs/databases.html#exploring-the-database-list",
    "title": "Working with Databases",
    "section": "Exploring the Database List",
    "text": "Exploring the Database List\nTo view and explore the database list, it’s possible to explore subsets of the data frame by row number with databases.loc:\n\n# View a subset consisting of rows 5 through 9\ndatabases.loc[5:9]\n\n\n\n\n\n\n\n\ndatabase_id\ndescription\n\n\n\n\n5\nBOP_2019M12\nBalance of Payments (BOP), 2019 M12\n\n\n6\nGFSYFALCS2014\nGovernment Finance Statistics Yearbook (GFSY 2...\n\n\n7\nGFSE2016\nGovernment Finance Statistics Yearbook (GFSY 2...\n\n\n8\nFM201510\nFiscal Monitor (FM) October 2015\n\n\n9\nGFSIBS2016\nGovernment Finance Statistics Yearbook (GFSY 2...\n\n\n\n\n\n\n\nOr, if you already know which database you want, you can fetch the corresponding code by searching for a string match using str.contains and subsetting the data frame for matching rows. For instance, here’s how to search for commodities data:\n\ndatabases[databases['description'].str.contains(\"Commodity\")]\n\n\n\n\n\n\n\n\ndatabase_id\ndescription\n\n\n\n\n305\nPCPS\nPrimary Commodity Price System (PCPS)\n\n\n306\nPCTOT\nCommodity Terms of Trade\n\n\n\n\n\n\n\nSee also Working with Large Data Frames for sample code showing how to view the full contents of the data frame in a browser window."
  },
  {
    "objectID": "docs/databases.html#best-practices",
    "href": "docs/databases.html#best-practices",
    "title": "Working with Databases",
    "section": "Best Practices",
    "text": "Best Practices\n\nCache the Database List: The database list rarely changes. Consider saving it locally if you’ll be making multiple queries. See Caching Strategy for sample code.\nSearch Strategically: Use specific search terms to find relevant databases. For example:\n\n“Price” for price indices\n“Trade” for trade statistics\n“Financial” for financial data\n\nUse a Browser Viewer: See Working with Large Data Frames for sample code showing how to view the full contents of the data frame in a browser window.\nNote Database IDs: Once you find a database you’ll use frequently, note its database ID for future reference."
  },
  {
    "objectID": "docs/databases.html#next-steps",
    "href": "docs/databases.html#next-steps",
    "title": "Working with Databases",
    "section": "Next Steps",
    "text": "Next Steps\nOnce you’ve identified the database you want to use, you’ll need to:\n\nGet the list of parameters for that database (see Parameters)\nUse those parameters to fetch your data (see Datasets)"
  },
  {
    "objectID": "docs/demo.html",
    "href": "docs/demo.html",
    "title": "Economic Growth and Gender Equality: An Analysis Using IMF Data",
    "section": "",
    "text": "This data analysis project aims to explore the relationship between economic growth and gender equality using imfp, which allows us to download data from IMF (International Monetary Fund). imfp can be integrated with other python tools to streamline the computational process. To demonstrate its functionality, the project experimented with a variety of visualization and analysis methods."
  },
  {
    "objectID": "docs/demo.html#executive-summary",
    "href": "docs/demo.html#executive-summary",
    "title": "Economic Growth and Gender Equality: An Analysis Using IMF Data",
    "section": "Executive Summary",
    "text": "Executive Summary\nIn this project, we explored the following:\n\nData Fetching\n\n\nMake API call to fetch 4 datasets: GII (Gender Inequality Index), Nominal GDP, GDP Deflator Index, Population series\n\n\nFeature Engineering\n\n\nCleaning: Convert GDP Deflator Index to a yearly basis and variables to numeric\nDependent Variable: Percent Change of Gender Inequality Index\nIndependent Variable: Percent Change of Real GDP per Capita\nTransform variables to display magnitude of change\nMerge the datasets\n\n\nData Visualization\n\n\nScatterplot\nTime Series Line Plots\nBarplot\nBoxplot\nHeatmap\n\n\nStatistical Analysis\n\n\nDescriptive Statistics\nRegression Analysis\nTime Series Analysis"
  },
  {
    "objectID": "docs/demo.html#utility-functions",
    "href": "docs/demo.html#utility-functions",
    "title": "Economic Growth and Gender Equality: An Analysis Using IMF Data",
    "section": "Utility Functions",
    "text": "Utility Functions\nThe integration of other Python tools not only streamlined our computational processes but also ensured consistency across the project.\nA custom module is written to simplify the process of making API calls and fetching information with imfp library. load_or_fetch_databases, load_or_fetch_parameters load_or_fetch_dataset load and retreive database, parameters, and dataset from a local or remote source. view_dataframe_in_browser displays dataframe in a web browser.\n\nimport os\nimport pickle\nfrom tempfile import NamedTemporaryFile\nimport pandas as pd\nimport imfp\nimport webbrowser\n\n\n# Function to display a DataFrame in a web browser\ndef view_dataframe_in_browser(df):\n    html = df.to_html()\n    with NamedTemporaryFile(delete=False, mode=\"w\", suffix=\".html\") as f:\n        url = \"file://\" + f.name\n        f.write(html)\n    webbrowser.open(url)\n\n\n# Function to load databases from CSV or fetch from API\ndef load_or_fetch_databases():\n    csv_path = os.path.join(\"data\", \"databases.csv\")\n\n    # Try to load from CSV\n    if os.path.exists(csv_path):\n        try:\n            return pd.read_csv(csv_path)\n        except Exception as e:\n            print(f\"Error loading CSV: {e}\")\n\n    # If CSV doesn't exist or couldn't be loaded, fetch from API\n    print(\"Fetching databases from IMF API...\")\n    databases = imfp.imf_databases()\n\n    # Save to CSV for future use\n    databases.to_csv(csv_path, index=False)\n    print(f\"Databases saved to {csv_path}\")\n\n    return databases\n\n\ndef load_or_fetch_parameters(database_name):\n    pickle_path = os.path.join(\"data\", f\"{database_name}.pickle\")\n\n    # Try to load from pickle file\n    if os.path.exists(pickle_path):\n        try:\n            with open(pickle_path, \"rb\") as f:\n                return pickle.load(f)\n        except Exception as e:\n            print(f\"Error loading pickle file: {e}\")\n\n    # If pickle doesn't exist or couldn't be loaded, fetch from API\n    print(f\"Fetching parameters for {database_name} from IMF API...\")\n    parameters = imfp.imf_parameters(database_name)\n\n    # Save to pickle file for future use\n    os.makedirs(\"data\", exist_ok=True)  # Ensure the data directory exists\n    with open(pickle_path, \"wb\") as f:\n        pickle.dump(parameters, f)\n    print(f\"Parameters saved to {pickle_path}\")\n\n    return parameters\n\n\ndef load_or_fetch_dataset(database_id, indicator):\n    file_name = f\"{database_id}.{indicator}.csv\"\n    csv_path = os.path.join(\"data\", file_name)\n\n    # Try to load from CSV file\n    if os.path.exists(csv_path):\n        try:\n            return pd.read_csv(csv_path)\n        except Exception as e:\n            print(f\"Error loading CSV file: {e}\")\n\n    # If CSV doesn't exist or couldn't be loaded, fetch from API\n    print(f\"Fetching dataset for {database_id}.{indicator} from IMF API...\")\n    dataset = imfp.imf_dataset(database_id=database_id, indicator=[indicator])\n\n    # Save to CSV file for future use\n    os.makedirs(\"data\", exist_ok=True)  # Ensure the data directory exists\n    dataset.to_csv(csv_path, index=False)\n    print(f\"Dataset saved to {csv_path}\")\n\n    return dataset"
  },
  {
    "objectID": "docs/demo.html#dependencies",
    "href": "docs/demo.html#dependencies",
    "title": "Economic Growth and Gender Equality: An Analysis Using IMF Data",
    "section": "Dependencies",
    "text": "Dependencies\nHere is a brief introduction about the packages used:\npandas: view and manipulate data frame\nmatplotlib.pyplot: make plots\nseaborn: make plots\nnumpy: computation\nLinearRegression: implement linear regression\ntabulate: format data into tables\nstatsmodels.api, adfuller, ARIMA,VAR,plot_acf,plot_pacf,mean_absolute_error,mean_squared_error, andgrangercausalitytests are specifically used for time series analysis.\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\nfrom tabulate import tabulate\nimport statsmodels.api as sm\nfrom statsmodels.tsa.stattools import adfuller\nfrom statsmodels.tsa.arima.model import ARIMA\nfrom statsmodels.tsa.vector_ar.var_model import VAR\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import mean_squared_error\nfrom statsmodels.tsa.stattools import grangercausalitytests"
  },
  {
    "objectID": "docs/demo.html#data-fetching",
    "href": "docs/demo.html#data-fetching",
    "title": "Economic Growth and Gender Equality: An Analysis Using IMF Data",
    "section": "Data Fetching",
    "text": "Data Fetching\nIn this section, we extracted four datasets through API calls: Gender Inequality Index(GII), GDP Deflator, Nominal GDP, and Population.\n\nfrom pathlib import Path\nPath(\"data\").mkdir(exist_ok=True)\n\n\n# Load or fetch databases\ndatabases = load_or_fetch_databases()\n\n# Filter out databases that contain a year in the description\ndatabases[\n  ~databases['description'].str.contains(r\"[\\d]{4}\", regex=True)\n]\n\n# view_dataframe_in_browser(databases)\n\n\n\n\n\n\n\n\ndatabase_id\ndescription\n\n\n\n\n25\nHPDD\nHistorical Public Debt (HPDD)\n\n\n34\nRAFIT2AGG\nRevenue Administration Fiscal Information Tool...\n\n\n47\nGENDER_EQUALITY\nGender Equality\n\n\n63\nPGCS\nPrivate and Public Capital Stock Dataset\n\n\n69\nGENDER_BUDGETING\nGender Budgeting\n\n\n125\nCPI\nConsumer Price Index (CPI)\n\n\n153\nIRFCL\nInternational Reserves and Foreign Currency Li...\n\n\n191\nIFS_DISCONTINUED\nInternational Financial Statistics (IFS), Disc...\n\n\n192\nEQ\nExport Quality\n\n\n193\nED\nExport Diversification\n\n\n226\nFISCALDECENTRALIZATION\nFiscal Decentralization\n\n\n291\nFDI\nFinancial Development Index\n\n\n292\nPSBSFAD\nPublic Sector Balance Sheet (PSBS)(FAD)\n\n\n293\nUNSDG_IMF_INPUTS\nSustainable Development Goals, IMF Inputs\n\n\n294\nCPIS\nCoordinated Portfolio Investment Survey (CPIS)\n\n\n295\nPCTOT\nCommodity Terms of Trade\n\n\n296\nFM\nFiscal Monitor (FM)\n\n\n297\nAFRREO\nSub-Saharan Africa Regional Economic Outlook (...\n\n\n298\nWHDREO\nWestern Hemisphere Regional Economic Outlook (...\n\n\n299\nMCDREO\nMiddle East and Central Asia Regional Economic...\n\n\n300\nAPDREO\nAsia and Pacific Regional Economic Outlook (AP...\n\n\n301\nBOPAGG\nBalance of Payments (BOP), World and Regional ...\n\n\n302\nPCPS\nPrimary Commodity Price System (PCPS)\n\n\n303\nCDIS\nCoordinated Direct Investment Survey (CDIS)\n\n\n304\nBOP\nBalance of Payments (BOP)\n\n\n305\nCOFER\nCurrency Composition of Official Foreign Excha...\n\n\n306\nDOT\nDirection of Trade Statistics (DOTS)\n\n\n307\nFAS\nFinancial Access Survey (FAS)\n\n\n308\nBOPSDMXUSD\nBalance of Payments (BOP), Global SDMX (US Dol...\n\n\n309\nNAMAIN_IDC_N\nSystem of National Accounts (SNA), NA_MAIN\n\n\n310\nGFSR\nGovernment Finance Statistics (GFS), Revenue\n\n\n311\nGFSSSUC\nGovernment Finance Statistics (GFS), Statement...\n\n\n312\nGFSCOFOG\nGovernment Finance Statistics (GFS), Expenditu...\n\n\n313\nGFSFALCS\nGovernment Finance Statistics (GFS), Financial...\n\n\n314\nGFSIBS\nGovernment Finance Statistics (GFS), Integrate...\n\n\n315\nGFSMAB\nGovernment Finance Statistics (GFS), Main Aggr...\n\n\n316\nGFSE\nGovernment Finance Statistics (GFS), Expense\n\n\n317\nIFS\nInternational Financial Statistics (IFS)\n\n\n318\nMFS\nMonetary and Financial Statistics (MFS)\n\n\n319\nRAFIT3P\nRA-FIT Round3 Completion and Participation Rates\n\n\n320\nFSI\nFinancial Soundness Indicators (FSIs)\n\n\n321\nFSIRE\nFinancial Soundness Indicators: Reporting enti...\n\n\n\n\n\n\n\nTwo databases were used: Gender Equality and International Financial Statistics (IFS).\n\ndatabases[databases['database_id'].isin(['GENDER_EQUALITY','IFS'])]\n\n\n\n\n\n\n\n\ndatabase_id\ndescription\n\n\n\n\n47\nGENDER_EQUALITY\nGender Equality\n\n\n317\nIFS\nInternational Financial Statistics (IFS)\n\n\n\n\n\n\n\nParameters are dictionary key names to make requests from the databases. “freq” stands for Frequency, such as Annual, Monthly, or Quarterly. “ref_area” stands for Geogrpahical Area, such as US (United States), JP (Japan), and GB (United Kindom). “indicator” refers to the code representing a specific dataset in the database. For example, if we display all the indicators for IFS database, the GDP deflator dataset has an input code of “NGDP_D_SA_IX” with a full name description of Gross Domestic Product, Deflator, Seasonally Adjusted, Index.\n\ndatasets = [\"GENDER_EQUALITY\", \"IFS\"]\nparams = {}\n\n# Fetch valid parameters for two datasets\nfor dataset in datasets:\n    params[dataset] = load_or_fetch_parameters(dataset)\n\n    valid_keys = list(params[dataset].keys())\n    print(f\"Parameters for {dataset}: \", valid_keys)\n\nParameters for GENDER_EQUALITY:  ['freq', 'ref_area', 'indicator']\nParameters for IFS:  ['freq', 'ref_area', 'indicator']\n\n\nWe paired the database with the specific dataset indicator to read and store the csv file.\n\ndatasets = {}\ndsets = [(\"GENDER_EQUALITY\", \"GE_GII\"), \n(\"IFS\", \"NGDP_D_SA_IX\"), \n(\"IFS\", \"NGDP_XDC\"), \n(\"IFS\", \"LP_PE_NUM\")]\n\nfor dset in dsets:\n    datasets[dset[0] + \".\" + dset[1]] = load_or_fetch_dataset(dset[0], dset[1])\n\n\n# \"Gender Inequality Index\"\nGII = \"GENDER_EQUALITY.GE_GII\"\n\n# \"Gross Domestic Product, Deflator, Seasonally Adjusted, Index\"\nGDP_deflator = \"IFS.NGDP_D_SA_IX\"\n\n# \"Gross Domestic Product, Nominal, Domestic Currency\"\nGDP_nominal = \"IFS.NGDP_XDC\"\n\n# \"Population, Persons, Number of\"\nGDP_population = \"IFS.LP_PE_NUM\"\n\n# Assign the datasets to new variables so we don't change the originals\nGII_data = datasets[GII]\nGDP_deflator_data = datasets[GDP_deflator]\nGDP_nominal_data = datasets[GDP_nominal]\nGDP_population_data = datasets[GDP_population]"
  },
  {
    "objectID": "docs/demo.html#feature-engineering",
    "href": "docs/demo.html#feature-engineering",
    "title": "Economic Growth and Gender Equality: An Analysis Using IMF Data",
    "section": "Feature Engineering",
    "text": "Feature Engineering\n\nData Cleaning\nSince the GDP deflator was reported on a quarterly basis, we converted it to a yearly basis.\n\n# Keep only rows with a partial string match for \"Q4\" in the time_period column\nGDP_deflator_data = GDP_deflator_data[GDP_deflator_data\n['time_period'].str.contains(\"Q4\")]\n\n\n# Split the time_period into year and quarter and keep the year only\nGDP_deflator_data.loc[:, 'time_period'] = GDP_deflator_data['time_period'].str[0:4]\n\nWe made all the variables numeric.\n\ndatasets = [GII_data, GDP_deflator_data, GDP_nominal_data, GDP_population_data]\n\nfor i, dataset in enumerate(datasets):    \n    # Use .loc to modify the columns\n    datasets[i].loc[:, 'obs_value'] = pd.to_numeric(datasets[i]['obs_value'], \n    errors='coerce')\n    datasets[i].loc[:, 'time_period'] = pd.to_numeric(datasets[i]['time_period'], \n    errors='coerce')\n    datasets[i].loc[:, 'unit_mult'] = pd.to_numeric(datasets[i]['unit_mult'], \n    errors='coerce')\n\n\n\nGII Percent Change: Dependent Variable\nWe kept percents as decimals to make them easy to work with for calculation. Different countries have different baseline level of economic growth and gender equality. We calculated the percent change to make them comparable.\nGender Inequality Index (GII) is a composite measure of gender inequality using three dimensions: reproducitve health, empowerment, and labor market. GII ranges from 0 to 1. While 0 indicates gender equality, 1 indicates gender inequality, possibly the worst outcome for one gender in all three dimensions.\n\n# Calculate percent change for each ref_area\n# First, create a copy and reset the index to avoid duplicate index issues\nGII_data_sorted = GII_data.sort_values(\n    ['ref_area', 'time_period']).reset_index(drop=True)\nGII_data['pct_change'] = GII_data_sorted.groupby('ref_area')['obs_value'].pct_change()\n\n# Display the first few rows of the updated dataset\nGII_data.head()\n\n\n\n\n\n\n\n\nfreq\nref_area\nindicator\nunit_mult\ntime_format\ntime_period\nobs_value\npct_change\n\n\n\n\n0\nA\nAF\nGE_GII\n0\nP1Y\n1990\n0.828244\nNaN\n\n\n1\nA\nAF\nGE_GII\n0\nP1Y\n1991\n0.817706\n-0.015156\n\n\n2\nA\nAF\nGE_GII\n0\nP1Y\n1992\n0.809806\n-0.016783\n\n\n3\nA\nAF\nGE_GII\n0\nP1Y\n1993\n0.803078\n-0.012651\n\n\n4\nA\nAF\nGE_GII\n0\nP1Y\n1994\n0.797028\n-0.013718\n\n\n\n\n\n\n\nWe subset the data frame to keep only the columns we want:\n\n# Create a new dataframe with only the required columns\nGII_data = GII_data[['ref_area', 'time_period', 'obs_value', 'pct_change']].copy()\n\nGII_data = GII_data.rename(columns = {\n    'ref_area': 'Country',\n    'time_period': 'Time',\n    'obs_value': 'GII',\n    'pct_change': 'GII_change'\n})\n\n# Display the first few rows of the new dataset\nGII_data.head()\n\n\n\n\n\n\n\n\nCountry\nTime\nGII\nGII_change\n\n\n\n\n0\nAF\n1990\n0.828244\nNaN\n\n\n1\nAF\n1991\n0.817706\n-0.015156\n\n\n2\nAF\n1992\n0.809806\n-0.016783\n\n\n3\nAF\n1993\n0.803078\n-0.012651\n\n\n4\nAF\n1994\n0.797028\n-0.013718\n\n\n\n\n\n\n\n\n\nGDP Percent Change: Independent Variable\nReal GDP per capita is a measure of a country’s economic welfare or standard of living. It is a great tool comparing a country’s economic development compared to other economies. Due to dataset access issue, we calculated Real GDP per capita by the following formula using GDP Deflator, Nominal GDP, and Population data:\n\\(\\text{Real GDP} = \\frac{\\text{Nominal GDP}}{\\text{GDP Deflator Index}}\\times 100\\)\n\\(\\text{Real GDP per capita} = \\frac{\\text{Real GDP}}{\\text{Population}}\\)\nGDP Deflator is a measure of price inflation and deflation with respect to a specific base year. The GDP deflator of a base year is equal to 100. A number of 200 indicates price inflation: the current year price of the good is twice its base year price. A number of 50 indicates price deflation: the current year price of the good is half its base year price. We kept the columns we want only for GDP-related datasets for easier table merging.\n\n# GDP Deflator Dataset\n# Create a new dataframe with only the required columns\nGDP_deflator_data = GDP_deflator_data[\n    ['ref_area', 'time_period', 'unit_mult', 'obs_value']].copy()\n\n# Display the first few rows of the new dataset\nGDP_deflator_data.head()\n\n\n\n\n\n\n\n\nref_area\ntime_period\nunit_mult\nobs_value\n\n\n\n\n3\nFI\n1990\n0\n73.200623\n\n\n7\nFI\n1991\n0\n73.984068\n\n\n11\nFI\n1992\n0\n74.654309\n\n\n15\nFI\n1993\n0\n75.619254\n\n\n19\nFI\n1994\n0\n77.937293\n\n\n\n\n\n\n\nNominal GDP is the total value of all goods and services produced in a given time period. It is usually higher than Real GDP and does not take into account cost of living in different countries or price change due to inflation/deflation.\n\n# GDP Nominal Data\n# Create a new dataframe with only the required columns\nGDP_nominal_data = GDP_nominal_data[\n    ['ref_area', 'time_period', 'unit_mult','obs_value']].copy()\n\n# Display the first few rows of the new dataset\nGDP_nominal_data.head()\n\n\n\n\n\n\n\n\nref_area\ntime_period\nunit_mult\nobs_value\n\n\n\n\n0\nNE\n2005\n6\n2418864.0\n\n\n1\nNE\n2006\n6\n2596972.0\n\n\n2\nNE\n2007\n6\n2762961.0\n\n\n3\nNE\n2008\n6\n3247835.0\n\n\n4\nNE\n2009\n6\n3403683.0\n\n\n\n\n\n\n\nPopulation is the total number of people living in a country at a given time. This is where the “per capita” comes from. Real GDP is the total value of all goods and services produced in a country adjusted for inflation. Real GDP per capita is the total economic output per person in a country.\n\n# GDP Population Data \n# Create a new dataframe with only the required columns\nGDP_population_data = GDP_population_data[\n    ['ref_area', 'time_period', 'unit_mult','obs_value']].copy()\n\n# Display the first few rows of the new dataset\nGDP_population_data.head()\n\n\n\n\n\n\n\n\nref_area\ntime_period\nunit_mult\nobs_value\n\n\n\n\n0\nGA\n1950\n3\n473.296\n\n\n1\nGA\n1951\n3\n476.381\n\n\n2\nGA\n1952\n3\n478.655\n\n\n3\nGA\n1953\n3\n480.536\n\n\n4\nGA\n1954\n3\n482.332\n\n\n\n\n\n\n\n\n# Combine all the datasets above for further calculation\nmerged_df = pd.merge(pd.merge(GDP_deflator_data,GDP_nominal_data, \non=['time_period', 'ref_area'], \nsuffixes=('_index', '_nominal'), \nhow='inner'), \nGDP_population_data, \non=['time_period', 'ref_area'], \nhow='inner')\n\nWe want to adjust GDP data based on unit multiplier. Unit multiplier stands for the number of zeroes we need to add to the value column. For example, in 1950, the observed population data for country GA (Georgia) was 473.296. With a unit muliplier of 3, the adjusted population would be 473296.\n\nmerged_df['adjusted_index'] = merged_df['obs_value_index'] * (10 ** (merged_df\n['unit_mult_index']))\nmerged_df['adjusted_nominal'] = merged_df['obs_value_nominal'] * (10 ** (merged_df\n['unit_mult_nominal']))\nmerged_df['adjusted_population'] = merged_df['obs_value'] * (10 ** (merged_df\n['unit_mult']))\n\n\n# Merged dataset\n# Create a new dataframe with only the required columns\nmerged_df = merged_df[['ref_area', 'time_period',\n'adjusted_nominal', 'adjusted_index', 'adjusted_population']].copy()\n\n# Display the first few rows of the dataset\nmerged_df.head()\n\n\n\n\n\n\n\n\nref_area\ntime_period\nadjusted_nominal\nadjusted_index\nadjusted_population\n\n\n\n\n0\nFI\n1990\n9.096400e+10\n73.200623\n4996220.0\n\n\n1\nFI\n1991\n8.691300e+10\n73.984068\n5019134.0\n\n\n2\nFI\n1992\n8.478600e+10\n74.654309\n5044928.0\n\n\n3\nFI\n1993\n8.561000e+10\n75.619254\n5071782.0\n\n\n4\nFI\n1994\n9.064600e+10\n77.937293\n5097090.0\n\n\n\n\n\n\n\nWe wanted to compute the Real GDP per capita.\n\n# Step 1: Real GDP = (Nominal GDP / GDP Deflator Index)*100\nmerged_df['Real_GDP_domestic'] = (merged_df['adjusted_nominal'] / merged_df[\n    'adjusted_index'])*100\n\n# Step 2: Real GDP per Capita = Real GDP / Population\nmerged_df['Real_GDP_per_capita'] = merged_df['Real_GDP_domestic'] / merged_df[\n    'adjusted_population']\n\n# Rename columns\nmerged_df = merged_df.rename(columns= {\n    \"ref_area\": \"Country\",\n    \"time_period\": \"Time\",\n    \"adjusted_nominal\": \"Nominal\",\n    \"adjusted_index\": \"Deflator\",\n    \"adjusted_population\": \"Population\",\n    \"Real_GDP_domestic\": \"Real GDP\",\n    \"Real_GDP_per_capita\": \"Real GDP per Capita\"\n}\n)\n# Check the results\nmerged_df.head()\n\n\n\n\n\n\n\n\nCountry\nTime\nNominal\nDeflator\nPopulation\nReal GDP\nReal GDP per Capita\n\n\n\n\n0\nFI\n1990\n9.096400e+10\n73.200623\n4996220.0\n1.242667e+11\n24872.143699\n\n\n1\nFI\n1991\n8.691300e+10\n73.984068\n5019134.0\n1.174753e+11\n23405.490395\n\n\n2\nFI\n1992\n8.478600e+10\n74.654309\n5044928.0\n1.135715e+11\n22512.011198\n\n\n3\nFI\n1993\n8.561000e+10\n75.619254\n5071782.0\n1.132119e+11\n22321.919259\n\n\n4\nFI\n1994\n9.064600e+10\n77.937293\n5097090.0\n1.163063e+11\n22818.181344\n\n\n\n\n\n\n\nWe calculated the percentage change in Real GDP per capita and put it in a new column.\n\n# Calculate percent change for each ref_area\nmerged_df[f'GDP_change'] = merged_df.sort_values(['Country', 'Time']).groupby(\n    'Country')['Real GDP per Capita'].pct_change()\n\n# Rename dataset\nGDP_data = merged_df\n\n# Display the first few rows of the dataset\nGDP_data.head()\n\n\n\n\n\n\n\n\nCountry\nTime\nNominal\nDeflator\nPopulation\nReal GDP\nReal GDP per Capita\nGDP_change\n\n\n\n\n0\nFI\n1990\n9.096400e+10\n73.200623\n4996220.0\n1.242667e+11\n24872.143699\nNaN\n\n\n1\nFI\n1991\n8.691300e+10\n73.984068\n5019134.0\n1.174753e+11\n23405.490395\n-0.058968\n\n\n2\nFI\n1992\n8.478600e+10\n74.654309\n5044928.0\n1.135715e+11\n22512.011198\n-0.038174\n\n\n3\nFI\n1993\n8.561000e+10\n75.619254\n5071782.0\n1.132119e+11\n22321.919259\n-0.008444\n\n\n4\nFI\n1994\n9.064600e+10\n77.937293\n5097090.0\n1.163063e+11\n22818.181344\n0.022232\n\n\n\n\n\n\n\n\n# GII and GDP\n# Merge the datasets\ncombined_data = pd.merge(GII_data, GDP_data, \non=[\"Country\", \"Time\"], \nhow = \"inner\")\n\n# Check the combined dataset\ncombined_data.head()\n\n\n\n\n\n\n\n\nCountry\nTime\nGII\nGII_change\nNominal\nDeflator\nPopulation\nReal GDP\nReal GDP per Capita\nGDP_change\n\n\n\n\n0\nAL\n2009\n0.246238\n-0.006176\n1.143936e+12\n95.997230\n2973044.0\n1.191635e+12\n400813.060656\nNaN\n\n\n1\nAL\n2010\n0.240877\n-0.009627\n1.239645e+12\n100.758353\n2948029.0\n1.230314e+12\n417334.584116\n0.041220\n\n\n2\nAL\n2011\n0.240131\n-0.009771\n1.300624e+12\n103.924160\n2928601.0\n1.251513e+12\n427341.491205\n0.023978\n\n\n3\nAL\n2012\n0.236440\n-0.009977\n1.332811e+12\n103.230605\n2914091.0\n1.291101e+12\n443054.328283\n0.036769\n\n\n4\nAL\n2013\n0.223407\n-0.009001\n1.350053e+12\n102.584604\n2903788.0\n1.316038e+12\n453214.302235\n0.022932"
  },
  {
    "objectID": "docs/demo.html#data-visualization",
    "href": "docs/demo.html#data-visualization",
    "title": "Economic Growth and Gender Equality: An Analysis Using IMF Data",
    "section": "Data Visualization",
    "text": "Data Visualization\n\nScatterplot\nScatterplot use dots to represent values of two numeric variables. The horizontal axis was the percent change in Real GDP per capita. The vertical axis was the percent change in Gender Inequality Index(GII). Different colors represented different countries. We used a linear regression line to display the overall pattern.\nBased on the scatterplot, it seemed like there was a slight positive relationship between GDP change and GII change as shown by the flat regression line. Gender inequality was decreasing (gender equality was improving) a little faster in country-years with low GDP growth and a little slower in country-years with high GDP growth.\n\n# Convert numeric columns to float\nnumeric_columns = [\n    'GII', 'GII_change', 'Nominal', 'Deflator', 'Population', \n    'Real GDP', 'Real GDP per Capita', 'GDP_change'\n]\nfor col in numeric_columns:\n    combined_data[col] = pd.to_numeric(combined_data[col], errors='coerce')\n\n# Count NAs\nprint(f\"Dropping {combined_data[numeric_columns].isna().sum()} rows with NAs\")\n\n# Drop NAs\ncombined_data = combined_data.dropna(subset=numeric_columns)\n\n# Plot the data points\nplt.figure(figsize=(8, 6))\nfor country in combined_data['Country'].unique():\n    country_data = combined_data[combined_data['Country'] == country]\n    plt.scatter(country_data['GDP_change'], country_data['GII_change'],\n             marker='o',linestyle='-', label=country)\nplt.title('Country-Year Analysis of GDP Change vs. GII Change')\nplt.xlabel('Percent Change in Real GDP per Capita (Country-Year)')\nplt.ylabel('Percent Change in GII (Country-Year)')\nplt.grid(True)\n\n# Prepare data for linear regression\nX = combined_data['GDP_change'].values.reshape(-1, 1)\ny = combined_data['GII_change'].values\n\n# Perform linear regression\nreg = LinearRegression().fit(X, y)\ny_pred = reg.predict(X)\n\n# Plot the regression line\nplt.plot(combined_data['GDP_change'], y_pred, color='red', linewidth=2)\n\nplt.show()\n\nDropping GII                     0\nGII_change             40\nNominal                 0\nDeflator                0\nPopulation              0\nReal GDP                0\nReal GDP per Capita     0\nGDP_change             38\ndtype: int64 rows with NAs\n\n\n\n\n\n\n\n\n\n\n\nTime Series Line Plot\nWe created separate line plots for GDP change and GII change over time for a few key countries might show the trends more clearly.\nUS: United States\nJP: Japan\nGB: United Kindom\nFR: France\nMX: Mexico\nBased on the line plots, we saw GDP change and GII change have different patterns. For example, in Mexico, when there was a big change in real GDP per captia in 1995, the change in GII was pretty stable.\n\n# Time Series Line plot for a few key countries\nselected_countries  = ['US', 'JP', 'GB', 'FR', 'MX']\ncombined_data_selected = combined_data[combined_data['Country'].isin(selected_countries)]\n\n# Set up the Plot Structure\nfig, ax = plt.subplots(2, 1, figsize=(8, 6), sharex=True)\n\n# Plot change in real GDP per capita over time\nsns.lineplot(data = combined_data_selected, \nx = \"Time\", \ny = \"GDP_change\", \nhue = \"Country\", \nax = ax[0])\nax[0].set_title(\"Percent Change in Real GDP per Capita Over Time\")\nax[0].set_ylabel(\"Percent Change in Real GDP per Capita\")\n\n# Plot change in GII over time\nsns.lineplot(data = combined_data_selected, \nx = \"Time\", \ny = \"GII_change\", \nhue = \"Country\", \nax = ax[1])\nax[1].set_title(\"Percent Change in GII over Time\")\nax[1].set_xlabel(\"Time\")\nax[1].set_ylabel(\"GII\")\n\nplt.tight_layout\nplt.show()\n\n\n\n\n\n\n\n\n\n\nBarplot\nWe used a barplot to show average changes in GII and GDP percent change for each country to visualize regions where inequality was improving or worsening.\nThis plot supported our previous observation how GII change seemed to be not be correlated with GDP change. We also saw that, for country SI, Solvenia, there seems to be a large improvement in gender inequality.\n\n# Barplot using average GII and GDP change\n# Calculate average change for each country\ncombined_data_avg = combined_data.groupby('Country')[\n    ['GII_change','GDP_change']].mean().reset_index()\n\n# Prepare to plot structure \nplt.figure(figsize = (18,10))\n\n# Create the barplot\ncombined_data_avg.plot(kind = 'bar', x = 'Country')\nplt.ylabel('Average Change')\nplt.xlabel('Country')\nplt.legend(['GII change', 'GDP change'])\nplt.grid(axis = 'y')\n\n# Show the plot\nplt.show()\n\n&lt;Figure size 1728x960 with 0 Axes&gt;\n\n\n\n\n\n\n\n\n\n\n\nBoxplot\nWe used boxplot to visualize the distribution of GDP and GII change by country, providing information about spread, median, and potential outliers. To provide a more informative view, we sequenced countries in an ascending order by the median of percent change in GDP.\nThe boxplot displayed a slight upward trend with no obvious pattern between GDP and GII change. In coutries with higher GDP change median, they also tend to have a larger spread of the GDP change. The median of GII change remained stable regardless of the magnitude of GDP change, implying weak or no association between GDP and GII change. We observed a potential outlier for country SI, Solvenia, which may explained its large improvement in Gender inequality.\n\n# Box plot for GII and GDP change\n# Melt the dataframe to long format for combined boxplot\ncombined_data_melted = combined_data.melt(id_vars=['Country'], \nvalue_vars=['GII_change', 'GDP_change'], \nvar_name='Change_Type', \nvalue_name='Value')\n\ngdp_medians = combined_data.groupby('Country')['GDP_change'].median().sort_values()\n\ncombined_data_melted['Country'] = pd.Categorical(combined_data_melted['Country'], \ncategories=gdp_medians.index, \nordered= True)\n\n# Prepare the plot structure\nplt.figure(figsize=(8, 6))\nsns.boxplot(data = combined_data_melted, \nx = \"Country\", \ny = 'Value', \nhue = 'Change_Type')\nplt.title('Distribution of GII and GDP change by Country')\nplt.xlabel('Country')\nplt.ylabel('Change')\nplt.legend(title = 'Change Type')\n\n# Show the plot\nplt.show()\n\n\n\n\n\n\n\n\n\n\nCorrelation Matrix\nWe created a heatmap to show the relationship between GII and GDP change.\nA positive correlation coefficient indicates a positive relationship: the larger the GDP change, the larger the GII change. A negative correlation coefficient indicates a negative relationship: the larger the GDP change, the smaller the GII change. A correlation coefficient closer to 0 indicates there is weak or no relationship.\nBased on the numeric values in the plot, there was a moderately strong positive correlation between GII and GDP change for country Estonia(EE) and Ireland(IE).\n\n# Calculate the correlation\ncountry_correlation = combined_data.groupby('Country')[\n    ['GII_change', 'GDP_change']].corr().iloc[0::2, -1].reset_index(name='Correlation')\n\n# Put the correlation value in a matrix format\ncorrelation_matrix = country_correlation.pivot(index='Country', \ncolumns='level_1', \nvalues='Correlation')\n\n# Check for NaN values in the correlation matrix\n# Replace NaNs with 0 or another value as appropriate\ncorrelation_matrix.fillna(0, inplace=True)  \n\n# Set up the plot structure\n# Adjust height to give more space for y-axis labels\nplt.figure(figsize=(8, 12))  \n\n# Plot the heatmap\nsns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \ncbar_kws={\"shrink\": .8}, \nlinewidths=.5)\n\n# Enhance axis labels and title\nplt.title('Heatmap for GII and GDP Change', fontsize=20)\nplt.xlabel('Variables', fontsize=16)\nplt.ylabel('Country', fontsize=16)\n\n# Improve readability of y-axis labels\nplt.yticks(fontsize=12)  # Adjust the font size for y-axis labels\n\n# Show the plot\nplt.show()"
  },
  {
    "objectID": "docs/demo.html#statistical-analysis",
    "href": "docs/demo.html#statistical-analysis",
    "title": "Economic Growth and Gender Equality: An Analysis Using IMF Data",
    "section": "Statistical Analysis",
    "text": "Statistical Analysis\n\nDescriptive Statistics\nThere was a total of 915 data points. The mean of the GII change in -0.0314868, which indicated the overall grand mean percent change in gender inequality index is -3.15%. The mean of the GDP change was 0.0234633, showing the overall grand mean percent change in real GDP per capita was 2.35%.\n\n# Generate summary statistics\ncombined_data.describe()\n\n\n\n\n\n\n\n\nGII\nGII_change\nNominal\nDeflator\nPopulation\nReal GDP\nReal GDP per Capita\nGDP_change\n\n\n\n\ncount\n896.000000\n896.000000\n8.960000e+02\n896.000000\n8.960000e+02\n8.960000e+02\n8.960000e+02\n896.000000\n\n\nmean\n0.238270\n-0.021738\n7.841185e+13\n85.362016\n4.507063e+07\n7.581775e+13\n9.919523e+05\n0.023793\n\n\nstd\n0.149157\n0.041293\n6.063567e+14\n21.125956\n1.255392e+08\n5.570436e+14\n3.854128e+06\n0.041931\n\n\nmin\n0.011690\n-0.552535\n2.187139e+09\n3.606364\n3.963240e+05\n5.217326e+09\n1.798422e+03\n-0.285847\n\n\n25%\n0.131004\n-0.030203\n1.101968e+11\n73.831673\n5.041634e+06\n1.500708e+11\n1.717820e+04\n0.004223\n\n\n50%\n0.184532\n-0.011172\n7.808172e+11\n88.700623\n1.032114e+07\n1.015802e+12\n3.545761e+04\n0.022361\n\n\n75%\n0.332871\n-0.003554\n2.497352e+12\n100.127034\n4.444512e+07\n2.914933e+12\n1.212319e+05\n0.043195\n\n\nmax\n0.788954\n0.210491\n9.546134e+15\n207.890742\n1.280842e+09\n7.920071e+15\n3.145315e+07\n0.241984\n\n\n\n\n\n\n\n\n\nRegression Analysis\nSimple linear regression as a foundational approach provide us with a basic understanding of the relationship between GDP change and GII change.\nBased on the summary, we concluded the following:\n\nBecasue p-value = 0.057, if we set alpha, the significance level, to be 0.05, we failed to reject the null hypothesis and conclude there was no significant relationship between percent change in real GDP per capita and gender inequality index.\nR-squared = 0.004. Only 0.4% of the variance in GII change could be explained by GDP change.\nWe were 95% confident that the interval from -0.003 to 0.169 captured the true slope of GDP change. Because 0 was included, we are uncertain about the effect of GDP change on GII chnage.\n\n\n# Get column data type summaries of combined_data\ncombined_data.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 896 entries, 1 to 973\nData columns (total 10 columns):\n #   Column               Non-Null Count  Dtype  \n---  ------               --------------  -----  \n 0   Country              896 non-null    object \n 1   Time                 896 non-null    object \n 2   GII                  896 non-null    float64\n 3   GII_change           896 non-null    float64\n 4   Nominal              896 non-null    float64\n 5   Deflator             896 non-null    float64\n 6   Population           896 non-null    float64\n 7   Real GDP             896 non-null    float64\n 8   Real GDP per Capita  896 non-null    float64\n 9   GDP_change           896 non-null    float64\ndtypes: float64(8), object(2)\nmemory usage: 77.0+ KB\n\n\n\n# Define independent and depenent variables\nX = combined_data['GDP_change']\ny = combined_data['GII_change']\n\n# Add a constant to indepdent variable to include an intercept\nX = sm.add_constant(X)\n\n# Fit a simple linear regresion model and print out the summary\nmodel = sm.OLS(y, X).fit()\nmodel.summary()\n\n\nOLS Regression Results\n\n\nDep. Variable:\nGII_change\nR-squared:\n0.000\n\n\nModel:\nOLS\nAdj. R-squared:\n-0.001\n\n\nMethod:\nLeast Squares\nF-statistic:\n0.1114\n\n\nDate:\nFri, 27 Jun 2025\nProb (F-statistic):\n0.739\n\n\nTime:\n12:42:47\nLog-Likelihood:\n1584.8\n\n\nNo. Observations:\n896\nAIC:\n-3166.\n\n\nDf Residuals:\n894\nBIC:\n-3156.\n\n\nDf Model:\n1\n\n\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\nconst\n-0.0220\n0.002\n-13.862\n0.000\n-0.025\n-0.019\n\n\nGDP_change\n0.0110\n0.033\n0.334\n0.739\n-0.054\n0.076\n\n\n\n\n\n\n\n\nOmnibus:\n872.466\nDurbin-Watson:\n1.570\n\n\nProb(Omnibus):\n0.000\nJarque-Bera (JB):\n62725.209\n\n\nSkew:\n-4.277\nProb(JB):\n0.00\n\n\nKurtosis:\n43.087\nCond. No.\n23.9\n\n\n\nNotes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\n\nTime Series Analysis\nTime series analysis allows us to explore how the relationship between GII and GDP change vary across different time periods, accounting for lagged effects.\nHere was a quick summary of the result:\n\nBoth GII and GDP change time series were stationary.\nPast GII change values significantly influenced cuurent GII change values.\nVAR model had good model performance on forecasting future values based on historical data.\nChanges in GDP did not cause/precde the changes in GII.\n\n\nADF Test: Stationality Assumption Check\nWe wanted to use Augmented Dickey-Fuller (ADF) test to check whether a time series was stationary, which was the model assumption for many time series models.\nStationarity implied constant mean and variance over time, making it more predictable and stable for forecasting.\nBased on the ADF test output, both GII and GDP change time series were stationary. We proceeded to the time series modeling section.\n\n# Augmented Dickey-Fuller (ADF) test for stationarity check\n# Create melted datasets\ncombined_data_time = combined_data.melt(id_vars=['Time', 'Country'], \nvalue_vars=['GII_change','GDP_change'], \nvar_name = 'Change_Type', \nvalue_name = 'Value')\nGII = combined_data_time[(combined_data_time['Change_Type'] == 'GII_change')]                         \n\nGDP = combined_data_time[(combined_data_time['Change_Type'] == 'GDP_change')]\n\n# Stationary Check\ndef adf_test(series):\n    result = adfuller(series.dropna())\n    print(f'ADF Statistic: {result[0]}')\n    print(f'p-value: {result[1]}')\n    if result[1] &lt; 0.05:\n        print(\"Series is stationary\")\n    else:\n        print(\"Series is not stationary\")\n\n# Output the result\nadf_test(GII['Value'])\nadf_test(GDP['Value'])\n\nADF Statistic: -13.258508444109324\np-value: 8.491362672400665e-25\nSeries is stationary\nADF Statistic: -13.53669426905047\np-value: 2.559492685554561e-25\nSeries is stationary\n\n\n\n\nVAR model: Examine variables separately\nWe fitted a VAR (Vector Autoreression) model to see the relationship between GII and GDP change. VAR is particularly useful when dealing with multivariate time series data and allows us to examine the interdependence between variables.\nBased on summary, here were several interpretations we could make:\n\nWe used AIC as the criteria for model selection. Lower value suggests a better fit.\nGiven that we wanted to predict GII change, we focused on the first set “Results for equation GII_change.”\nPast GII_change values significantly influenced current GII_change, as shown in the small p-values of lags 1 and 2.\nLag 2 of GDP_change had a relatively low p-value but is not statistically significant.\n\n\n# Split the dataset into training and testing sets\nsplit_ratio = 0.7\nsplit_index = int(len(combined_data) * split_ratio)\n\n# Training set is used to fit the model\ntrain_data = combined_data.iloc[:split_index]\n\n# Testing set is used for validation\ntest_data = combined_data.iloc[split_index:]\n\nprint(f\"Training data: {train_data.shape}\")\nprint(f\"Test data: {test_data.shape}\")\n\nTraining data: (627, 10)\nTest data: (269, 10)\n\n\n\n# Fit a VAR model \ntime_model = VAR(train_data[['GII_change', 'GDP_change']])\ntime_model_fitted = time_model.fit(maxlags = 15, ic=\"aic\")\n\n# Print out the model summary\ntime_model_fitted.summary()\n\n  Summary of Regression Results   \n==================================\nModel:                         VAR\nMethod:                        OLS\nDate:           Fri, 27, Jun, 2025\nTime:                     12:42:47\n--------------------------------------------------------------------\nNo. of Equations:         2.00000    BIC:                   -12.6388\nNobs:                     624.000    HQIC:                  -12.6996\nLog likelihood:           2217.52    FPE:                2.93645e-06\nAIC:                     -12.7383    Det(Omega_mle):     2.87166e-06\n--------------------------------------------------------------------\nResults for equation GII_change\n================================================================================\n                   coefficient       std. error           t-stat            prob\n--------------------------------------------------------------------------------\nconst                -0.014401         0.002527           -5.698           0.000\nL1.GII_change         0.206183         0.040171            5.133           0.000\nL1.GDP_change         0.008941         0.037668            0.237           0.812\nL2.GII_change         0.147039         0.040539            3.627           0.000\nL2.GDP_change        -0.038093         0.037741           -1.009           0.313\nL3.GII_change         0.071829         0.040373            1.779           0.075\nL3.GDP_change         0.041997         0.037485            1.120           0.263\n================================================================================\n\nResults for equation GDP_change\n================================================================================\n                   coefficient       std. error           t-stat            prob\n--------------------------------------------------------------------------------\nconst                 0.017922         0.002668            6.719           0.000\nL1.GII_change        -0.021878         0.042400           -0.516           0.606\nL1.GDP_change         0.132221         0.039758            3.326           0.001\nL2.GII_change         0.124973         0.042789            2.921           0.003\nL2.GDP_change         0.025632         0.039835            0.643           0.520\nL3.GII_change        -0.063330         0.042614           -1.486           0.137\nL3.GDP_change         0.146934         0.039565            3.714           0.000\n================================================================================\n\nCorrelation matrix of residuals\n              GII_change  GDP_change\nGII_change      1.000000   -0.033903\nGDP_change     -0.033903    1.000000\n\n\n\n\n\nVAR Model: Forecasting\nWe applied the model learned above to the test data. Based on the plot, the forecast values seem to follow the actual data well, indicating a good model fit caputuring the underlying trends.\n\n# Number of steps to forecast (length of the test set)\nn_steps = len(test_data)\n\n# Get the last values from the training set for forecasting\nforecast_input = train_data[\n    ['GII_change', 'GDP_change']].values[-time_model_fitted.k_ar:]\n\n# Forecasting\nforecast = time_model_fitted.forecast(y=forecast_input, steps=n_steps)\n\n# Create a DataFrame for the forecasted values\nforecast_df = pd.DataFrame(forecast, index=test_data.index, \ncolumns=['GII_forecast', 'GDP_forecast'])\n\n# Ensure the index of the forecast_df matches the test_data index\nforecast_df.index = test_data.index\n\n\nplt.figure(figsize=(8, 6))\nplt.plot(train_data['GII_change'], label='Training GII', color='blue')\nplt.plot(test_data['GII_change'], label='Actual GII', color='orange')\nplt.plot(forecast_df['GII_forecast'], label='Forecasted GII', color='green')\nplt.title('GII Change Forecast vs Actual')\nplt.legend()\nplt.show()\n\nplt.figure(figsize=(8, 6))\nplt.plot(train_data['GDP_change'], label='Training GDP', color='blue')\nplt.plot(test_data['GDP_change'], label='Actual GDP', color='orange')\nplt.plot(forecast_df['GDP_forecast'], label='Forecasted GDP', color='green')\nplt.title('GDP Change Forecast vs Actual')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVAR Model: Model Performance\nLow values of both MAE and RMSE indicate good model performance with small average errors in predictions.\n\nmae_gii = mean_absolute_error(test_data['GII_change'], forecast_df['GII_forecast'])\nmae_gdp = mean_absolute_error(test_data['GDP_change'], forecast_df['GDP_forecast'])\n\nprint(f'Mean Absolute Error for GII: {mae_gii}')\nprint(f'Mean Absolute Error for GDP: {mae_gdp}')\n\nMean Absolute Error for GII: 0.02163427421854603\nMean Absolute Error for GDP: 0.027874530660148857\n\n\n\nrmse_gii = np.sqrt(mean_squared_error(test_data['GII_change'], \nforecast_df['GII_forecast']))\nrmse_gdp = np.sqrt(mean_squared_error(test_data['GDP_change'], \nforecast_df['GDP_forecast']))\n\nprint(f'RMSE for GII: {rmse_gii}')\nprint(f'RMSE for GDP: {rmse_gdp}')\n\nRMSE for GII: 0.0400826273209931\nRMSE for GDP: 0.03867925511599023\n\n\n\n\nVAR Model: Granger causality test\nGranger causality test evaluates whether one time series can predict another.\nBased on the output, the lowest p-value is when lag = 2. However, because p-value &gt; 0.05, we fail to reject the null hypothesis and conclude the GDP_change does not Granger-cause the GII_change.\n\n# Perform the Granger causality test\nmax_lag = 3\ntest_result = grangercausalitytests(train_data[['GII_change', 'GDP_change']], max_lag,\n verbose=True)\n\n\nGranger Causality\nnumber of lags (no zero) 1\nssr based F test:         F=0.1149  , p=0.7348  , df_denom=623, df_num=1\nssr based chi2 test:   chi2=0.1154  , p=0.7340  , df=1\nlikelihood ratio test: chi2=0.1154  , p=0.7341  , df=1\nparameter F test:         F=0.1149  , p=0.7348  , df_denom=623, df_num=1\n\nGranger Causality\nnumber of lags (no zero) 2\nssr based F test:         F=0.4787  , p=0.6198  , df_denom=620, df_num=2\nssr based chi2 test:   chi2=0.9652  , p=0.6172  , df=2\nlikelihood ratio test: chi2=0.9644  , p=0.6174  , df=2\nparameter F test:         F=0.4787  , p=0.6198  , df_denom=620, df_num=2\n\nGranger Causality\nnumber of lags (no zero) 3\nssr based F test:         F=0.6797  , p=0.5647  , df_denom=617, df_num=3\nssr based chi2 test:   chi2=2.0623  , p=0.5596  , df=3\nlikelihood ratio test: chi2=2.0589  , p=0.5603  , df=3\nparameter F test:         F=0.6797  , p=0.5647  , df_denom=617, df_num=3"
  },
  {
    "objectID": "docs/demo.html#conclusion",
    "href": "docs/demo.html#conclusion",
    "title": "Economic Growth and Gender Equality: An Analysis Using IMF Data",
    "section": "Conclusion",
    "text": "Conclusion\nIn wrapping up our analysis, we found no evidence to support a significant relationship between the Change in Real GDP per capita and the Change in the Gender Inequality Index (GII). This suggests that economic growth may not have a direct impact on gender equality. However, our findings open the door to questions for future research."
  },
  {
    "objectID": "docs/demo.html#future-directions",
    "href": "docs/demo.html#future-directions",
    "title": "Economic Growth and Gender Equality: An Analysis Using IMF Data",
    "section": "Future Directions",
    "text": "Future Directions\nFirst, we must consider what other factors might influence the relationship between GDP and GII change. The GII is a composite index, shaped by a myriad of social factors, including cultural norms, legal frameworks, and environmental shifts. Future studies could benefit from incorporating additional predictors into the analysis and exploring the interaction between economic growth and gender equality within specific country contexts.\nSecond, there’s potential to enhance the predictive power of our Vector Autoregression (VAR) time series model. While we established that GDP change does not cause GII change, our model performed well in forecasting trends for both variables independently. In practice, policymakers may want to forecast GII trends independently of GDP if they are implementing gender-focused policies. Future research could investigate time series modeling to further unravel the dynamics of GII and GDP changes.\nSo, as we wrap up this chapter, let’s keep our curiosity alive and our questions flowing. After all, every end is just a new beginning in the quest for knowledge!"
  },
  {
    "objectID": "docs/demo.html#about-the-author",
    "href": "docs/demo.html#about-the-author",
    "title": "Economic Growth and Gender Equality: An Analysis Using IMF Data",
    "section": "About the Author",
    "text": "About the Author\n\n\n\nHi there! My name is Jenny, and I’m a third-year student at University of California, Davis, double majoring in Statistics and Psychology. I’ve always been interested in becoming a data analyst working in tech, internet, or research industries. Interning at Promptly Technologies helped me learn a ton. A quick fun fact for me is that my MBTI is ISFJ (Defender)!\n\n  Email    LinkedIn    GitHub"
  },
  {
    "objectID": "docs/parameters.html",
    "href": "docs/parameters.html",
    "title": "Working with Parameters",
    "section": "",
    "text": "Once you have a database_id, it’s possible to make a call to imf_dataset to fetch the entire database:\n\nimport imfp\nimport pandas as pd\n\n# Set float format to 2 decimal places for pandas display output\npd.set_option('display.float_format', lambda x: '%.2f' % x)\n\nimfp.imf_dataset(database_id)\n\nHowever, while this will succeed for a few small databases, it will fail for all of the larger ones. And even in the rare case when it succeeds, fetching an entire database can take a long time. You’re much better off supplying additional filter parameters to reduce the size of your request.\nRequests to databases available through the IMF API are complicated by the fact that each database uses a different set of parameters when making a request. (At last count, there were 43 unique parameters used in making API requests from the various databases!) You also have to have the list of valid input codes for each parameter. The imf_parameters function solves this problem. Use the function to obtain the full list of parameters and valid input codes for a given database."
  },
  {
    "objectID": "docs/parameters.html#filtering-imf-dataset-requests-with-parameters",
    "href": "docs/parameters.html#filtering-imf-dataset-requests-with-parameters",
    "title": "Working with Parameters",
    "section": "",
    "text": "Once you have a database_id, it’s possible to make a call to imf_dataset to fetch the entire database:\n\nimport imfp\nimport pandas as pd\n\n# Set float format to 2 decimal places for pandas display output\npd.set_option('display.float_format', lambda x: '%.2f' % x)\n\nimfp.imf_dataset(database_id)\n\nHowever, while this will succeed for a few small databases, it will fail for all of the larger ones. And even in the rare case when it succeeds, fetching an entire database can take a long time. You’re much better off supplying additional filter parameters to reduce the size of your request.\nRequests to databases available through the IMF API are complicated by the fact that each database uses a different set of parameters when making a request. (At last count, there were 43 unique parameters used in making API requests from the various databases!) You also have to have the list of valid input codes for each parameter. The imf_parameters function solves this problem. Use the function to obtain the full list of parameters and valid input codes for a given database."
  },
  {
    "objectID": "docs/parameters.html#understanding-filter-parameters",
    "href": "docs/parameters.html#understanding-filter-parameters",
    "title": "Working with Parameters",
    "section": "Understanding Filter Parameters",
    "text": "Understanding Filter Parameters\nEach database available through the IMF API has its own set of parameters that can be used to filter and specify the data you want to retrieve.\nEach parameter will be a column in the data. Each row in the data will contain a value for that parameter. The parameter will always be a categorical variable, meaning that it can take only a limited set of values. We refer to these values as “input codes,” because you can input them in your API request to filter the data.\nWhat this means, though, is that before making an API request to retrieve data, you need to know what the available filtering parameters are for the database, and what codes you can use for filtering the data by each parameter.\nThere are two main functions for working with parameters:\n\nimf_parameters(): Get the full list of parameters and valid input codes for a database\nimf_parameter_defs(): Get text descriptions of what each parameter represents"
  },
  {
    "objectID": "docs/parameters.html#discovering-available-parameters",
    "href": "docs/parameters.html#discovering-available-parameters",
    "title": "Working with Parameters",
    "section": "Discovering Available Parameters",
    "text": "Discovering Available Parameters\nTo get started, you’ll need to know what parameters are available for your chosen database. Use imf_parameters() to get this information:\n\nimport imfp\n\n# Fetch list of valid parameters for the Primary Commodity Price System database\nparams = imfp.imf_parameters(\"PCPS\")\n\n# View the available parameter names\nparams.keys()\n\ndict_keys(['freq', 'ref_area', 'commodity', 'unit_measure'])\n\n\nThe function returns a dictionary of data frames.\nEach key in the dictionary corresponds to a parameter used in making requests from the database. The value for each key is a data frame with the following columns:\n\ninput_code: The valid codes you can use for that parameter\ndescription: A short text description of what each code represents\n\nFor example, to see the valid codes for the freq (frequency) parameter:\n\n# View the data frame of valid input codes for the frequency parameter\nparams['freq']\n\n\n\n\n\n\n\n\ninput_code\ndescription\n\n\n\n\n0\nA\nAnnual\n\n\n1\nM\nMonthly\n\n\n2\nQ\nQuarterly"
  },
  {
    "objectID": "docs/parameters.html#parameter-definitions",
    "href": "docs/parameters.html#parameter-definitions",
    "title": "Working with Parameters",
    "section": "Parameter Definitions",
    "text": "Parameter Definitions\nIf the parameter name is not self-explanatory, you can use the imf_parameter_defs() function to get a text description of what each parameter represents.\n\n# Get descriptions of what each parameter means\nparams_defs = imfp.imf_parameter_defs(\"PCPS\")\n\nparams_defs\n\n\n\n\n\n\n\n\nparameter\ndescription\n\n\n\n\n0\nfreq\nFrequency\n\n\n1\nref_area\nGeographical Areas\n\n\n2\ncommodity\nIndicator\n\n\n3\nunit_measure\nUnit"
  },
  {
    "objectID": "docs/parameters.html#supplying-parameters",
    "href": "docs/parameters.html#supplying-parameters",
    "title": "Working with Parameters",
    "section": "Supplying Parameters",
    "text": "Supplying Parameters\n\nBasic Approach (Recommended for Most Users)\nTo make a request to fetch data from the IMF API, just call imf_dataset with the database ID and keyword arguments for each parameter, where the keyword argument name is the parameter name and the value is the list of codes you want.\nFor instance, on exploring the freq parameter of the Primary Commodity Price System database above, we found that the frequency can take one of three values: “A” for annual, “Q” for quarterly, and “M” for monthly. Thus, to request annual data, we can call imf_dataset with freq = [\"A\"].\nHere’s a complete example that fetches annual coal prices for the years 2000 through 2015:\n\n# Example: Get annual coal prices\ndf = imfp.imf_dataset(\n    database_id=\"PCPS\",\n    freq=[\"A\"],  # Annual frequency\n    commodity=[\"PCOAL\"],  # Coal prices\n    start_year=2000,\n    end_year=2015\n)\n\n\n\nAdvanced Approaches\nFor more complex queries, there are two programmatic ways to supply parameters to imf_dataset. These approaches are particularly useful when you need to filter parameters based on their descriptions or when working with multiple parameter values.\n\n1. List Arguments with Parameter Filtering\nThis approach uses string matching to find the correct parameter codes before passing them to imf_dataset:\n\n# Fetch the input code column of the freq parameter...\nselected_freq = list(\n    params['freq']['input_code'][\n        # ...where the description contains \"Annual\"\n        params['freq']['description'].str.contains(\"Annual\")\n    ]\n)\n\n# Fetch the input code column of the commodity parameter...\nselected_commodity = list(\n    params['commodity']['input_code'][\n        # ...where the description contains \"Coal\"\n        params['commodity']['description'].str.contains(\"Coal\")\n    ]\n)\n\n# Fetch the input code column of the unit_measure parameter...\nselected_unit_measure = list(\n    params['unit_measure']['input_code'][\n        # ...where the description contains \"Index\"\n        params['unit_measure']['description'].str.contains(\"Index\")\n    ]\n)\n\n# Request data from the API using the filtered parameter code lists\ndf = imfp.imf_dataset(\n    database_id=\"PCPS\",\n    freq=selected_freq,\n    commodity=selected_commodity,\n    unit_measure=selected_unit_measure,\n    start_year=2000,\n    end_year=2015\n)\n\ndf.head()\n\n\n\n\n\n\n\n\nfreq\nref_area\ncommodity\nunit_measure\nunit_mult\ntime_format\ntime_period\nobs_value\n\n\n\n\n0\nA\nW00\nPCOAL\nIX\n0\nP1Y\n2000\n39.3510230293202\n\n\n1\nA\nW00\nPCOAL\nIX\n0\nP1Y\n2001\n49.3378587284039\n\n\n2\nA\nW00\nPCOAL\nIX\n0\nP1Y\n2002\n39.4949091648006\n\n\n3\nA\nW00\nPCOAL\nIX\n0\nP1Y\n2003\n43.2878876950788\n\n\n4\nA\nW00\nPCOAL\nIX\n0\nP1Y\n2004\n82.9185858052862\n\n\n\n\n\n\n\n\n\n2. Parameters Dictionary Approach\nThis approach modifies the parameters dictionary directly and passes the entire filtered dictionary to imf_dataset as a single parameters keyword argument. This is more concise but requires understanding how the parameters dictionary works:\n\n# Copy the params dictionary\nmodified_params = params.copy()\n\n# Overwrite the data frame for each parameter in the dictionary with filtered rows\nmodified_params['freq'] = params['freq'][\n    # ...where the input code description for freq contains \"Annual\"\n    params['freq']['description'].str.contains(\"Annual\")\n]\nmodified_params['commodity'] = params['commodity'][\n    # ...where the input code description for commodity contains \"Coal\"\n    params['commodity']['description'].str.contains(\"Coal\")\n]\nmodified_params['unit_measure'] = params['unit_measure'][\n    # ...where the input code description for unit_measure contains \"Index\"\n    params['unit_measure']['description'].str.contains(\"Index\")\n]\n\n# Pass the modified dictionary to imf_dataset\ndf = imfp.imf_dataset(\n    database_id=\"PCPS\",\n    parameters=modified_params,\n    start_year=2000,\n    end_year=2015\n)\n\ndf.head()\n\n\n\n\n\n\n\n\nfreq\nref_area\ncommodity\nunit_measure\nunit_mult\ntime_format\ntime_period\nobs_value\n\n\n\n\n0\nA\nW00\nPCOAL\nIX\n0\nP1Y\n2000\n39.3510230293202\n\n\n1\nA\nW00\nPCOAL\nIX\n0\nP1Y\n2001\n49.3378587284039\n\n\n2\nA\nW00\nPCOAL\nIX\n0\nP1Y\n2002\n39.4949091648006\n\n\n3\nA\nW00\nPCOAL\nIX\n0\nP1Y\n2003\n43.2878876950788\n\n\n4\nA\nW00\nPCOAL\nIX\n0\nP1Y\n2004\n82.9185858052862\n\n\n\n\n\n\n\nNote that when using the parameters dictionary approach, you cannot combine it with individual parameter arguments. If you supply a parameters argument, any other keyword arguments for individual parameters will be ignored."
  },
  {
    "objectID": "docs/usage.html",
    "href": "docs/usage.html",
    "title": "Suggestions for Usage",
    "section": "",
    "text": "Unfortunately, many of the indicators listed as available in the lists of input codes returned by imf_parameters() are not actually available. This is a deficiency of the API rather than the library; someone at the IMF presumably intended to provide these indicators at some point, but never got around to it.\nThe only way to be certain whether an indicator is available is to make a request to the API and see if it succeeds. If not, you will receive an error message indicating that no data was found for your parameters. In general, if you see this message, you should try making a less restrictive version of your request. For instance, if your request returns no data for an indicator for a given country and time period, you can omit the country or time period parameter and try again. If you still get no data, that indicator is not actually available through the API.\nWhile it is not fully predictable which indicators will be available, as a general rule you can expect to get unadjusted series but not adjusted ones. For instance, real and per capita GDP are not available (although they are listed) through the API, but nominal GDP is. The API does, however, make available all the adjustment variables you would need to adjust the data yourself. See the Common Data Transformations section below for examples of how to make adjustments."
  },
  {
    "objectID": "docs/usage.html#determining-data-availability",
    "href": "docs/usage.html#determining-data-availability",
    "title": "Suggestions for Usage",
    "section": "",
    "text": "Unfortunately, many of the indicators listed as available in the lists of input codes returned by imf_parameters() are not actually available. This is a deficiency of the API rather than the library; someone at the IMF presumably intended to provide these indicators at some point, but never got around to it.\nThe only way to be certain whether an indicator is available is to make a request to the API and see if it succeeds. If not, you will receive an error message indicating that no data was found for your parameters. In general, if you see this message, you should try making a less restrictive version of your request. For instance, if your request returns no data for an indicator for a given country and time period, you can omit the country or time period parameter and try again. If you still get no data, that indicator is not actually available through the API.\nWhile it is not fully predictable which indicators will be available, as a general rule you can expect to get unadjusted series but not adjusted ones. For instance, real and per capita GDP are not available (although they are listed) through the API, but nominal GDP is. The API does, however, make available all the adjustment variables you would need to adjust the data yourself. See the Common Data Transformations section below for examples of how to make adjustments."
  },
  {
    "objectID": "docs/usage.html#working-with-large-data-frames",
    "href": "docs/usage.html#working-with-large-data-frames",
    "title": "Suggestions for Usage",
    "section": "Working with Large Data Frames",
    "text": "Working with Large Data Frames\n\nInspecting Data\nimfp outputs data in pandas DataFrames, so you will want to use the pandas package for its functions for viewing and manipulating this object type.\nFor large datasets, you can use the pandas library’s info() method to get a quick summary of the data frame, including the number of rows and columns, the count of non-missing values, the column names, and the data types.\n\nimport imfp\nimport pandas as pd\n\n# Set float format to 2 decimal places for pandas display output\npd.set_option('display.float_format', lambda x: '%.2f' % x)\n\ndf: pd.DataFrame = imfp.imf_dataset(\n    database_id=\"PCPS\",\n    commodity=[\"PCOAL\"],\n    unit_measure=[\"IX\"],\n    start_year=2000, end_year=2001\n)\n\n# Quick summary of DataFrame\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 34 entries, 0 to 23\nData columns (total 8 columns):\n #   Column        Non-Null Count  Dtype \n---  ------        --------------  ----- \n 0   freq          34 non-null     object\n 1   ref_area      34 non-null     object\n 2   commodity     34 non-null     object\n 3   unit_measure  34 non-null     object\n 4   unit_mult     34 non-null     object\n 5   time_format   34 non-null     object\n 6   time_period   34 non-null     object\n 7   obs_value     34 non-null     object\ndtypes: object(8)\nmemory usage: 2.4+ KB\n\n\nAlternatively, you can use the head() method to view the first 5 rows of the data frame.\n\n# View first 5 rows of DataFrame\ndf.head()\n\n\n\n\n\n\n\n\nfreq\nref_area\ncommodity\nunit_measure\nunit_mult\ntime_format\ntime_period\nobs_value\n\n\n\n\n0\nA\nW00\nPCOAL\nIX\n0\nP1Y\n2000\n39.3510230293202\n\n\n1\nA\nW00\nPCOAL\nIX\n0\nP1Y\n2001\n49.3378587284039\n\n\n0\nQ\nW00\nPCOAL\nIX\n0\nP3M\n2000-Q1\n36.2253202528364\n\n\n1\nQ\nW00\nPCOAL\nIX\n0\nP3M\n2000-Q2\n38.3233649120962\n\n\n2\nQ\nW00\nPCOAL\nIX\n0\nP3M\n2000-Q3\n39.5896503864216\n\n\n\n\n\n\n\n\n\nCleaning Data\n\nNumeric Conversion\nAll data is returned from the IMF API as a text (object) data type, so you will want to cast numeric columns to numeric.\n\n# Numeric columns\nnumeric_cols = [\"unit_mult\", \"obs_value\"]\n\n# Cast numeric columns\ndf[numeric_cols] = df[numeric_cols].apply(pd.to_numeric)\n\n\n\nCategorical Conversion\nYou can also convert string columns to categorical types for better memory usage.\n\n# Convert categorical columns like ref_area and indicator to category type\ncategorical_cols = [\n  \"freq\",\n  \"ref_area\",\n  \"commodity\",\n  \"unit_measure\",\n  \"time_format\"\n]\n\ndf[categorical_cols] = df[categorical_cols].astype(\"category\")\n\n\n\nNA Removal\nAfter conversion, you may want to drop any rows with missing values.\n\n# Drop rows with missing values\ndf = df.dropna()\n\n\n\nTime Period Conversion\nThe time_period column can be more difficult to work with, because it may be differently formatted depending on the frequency of the data.\nAnnual data will be formatted as a four-digit year, such as “2000”, which can be trivially converted to numeric.\nHowever, quarterly data will be formatted as “2000-Q1”, and monthly data will be formatted like “2000-01”.\nYou can use the pandas library’s to_datetime() method with the format=\"mixed\" argument to convert this column to a datetime object in a format-agnostic way:\n\n# Convert time_period to datetime\ndf[\"datetime\"] = pd.to_datetime(df[\"time_period\"], format=\"mixed\")\ndf[[\"freq\", \"datetime\"]].head()\n\n\n\n\n\n\n\n\nfreq\ndatetime\n\n\n\n\n0\nA\n2000-01-01\n\n\n1\nA\n2001-01-01\n\n\n0\nQ\n2000-01-01\n\n\n1\nQ\n2000-04-01\n\n\n2\nQ\n2000-07-01\n\n\n\n\n\n\n\nAlternatively, you can split the time_period column into separate columns for year, quarter, and month, and then convert each to a numeric value:\n\n# Split time_period into separate columns\ndf[\"year\"] = df[\"time_period\"].str.extract(r\"(\\d{4})\")[0]\ndf[\"quarter\"] = df[\"time_period\"].str.extract(r\"Q(\\d{1})\")[0]\ndf[\"month\"] = df[\"time_period\"].str.extract(r\"-(\\d{2})\")[0]\n\n# Convert year, quarter, and month to numeric\ndf[\"year\"] = pd.to_numeric(df[\"year\"])\ndf[\"quarter\"] = pd.to_numeric(df[\"quarter\"])\ndf[\"month\"] = pd.to_numeric(df[\"month\"])\n\ndf[[\"time_period\", \"year\", \"quarter\", \"month\"]].head()\n\n\n\n\n\n\n\n\ntime_period\nyear\nquarter\nmonth\n\n\n\n\n0\n2000\n2000\nNaN\nNaN\n\n\n1\n2001\n2001\nNaN\nNaN\n\n\n0\n2000-Q1\n2000\n1.00\nNaN\n\n\n1\n2000-Q2\n2000\n2.00\nNaN\n\n\n2\n2000-Q3\n2000\n3.00\nNaN\n\n\n\n\n\n\n\n\n\n\nSummarizing Data\nAfter converting columns to numeric, you can use the describe() function to get a quick summary of the statistical properties of these, including the count of rows, the mean, the standard deviation, the minimum and maximum values, and the quartiles.\n\n# Statistical summary\ndf.describe()\n\n\n\n\n\n\n\n\nunit_mult\nobs_value\ndatetime\nyear\nquarter\nmonth\n\n\n\n\ncount\n34.00\n34.00\n34\n34.00\n8.00\n24.00\n\n\nmean\n0.00\n44.34\n2000-11-28 21:52:56.470588288\n2000.50\n2.50\n6.50\n\n\nmin\n0.00\n35.59\n2000-01-01 00:00:00\n2000.00\n1.00\n1.00\n\n\n25%\n0.00\n39.22\n2000-06-08 12:00:00\n2000.00\n1.75\n3.75\n\n\n50%\n0.00\n44.35\n2000-12-16 12:00:00\n2000.50\n2.50\n6.50\n\n\n75%\n0.00\n50.11\n2001-05-24 06:00:00\n2001.00\n3.25\n9.25\n\n\nmax\n0.00\n51.48\n2001-12-01 00:00:00\n2001.00\n4.00\n12.00\n\n\nstd\n0.00\n5.76\nNaN\n0.51\n1.20\n3.53\n\n\n\n\n\n\n\n\n\nViewing Data\nFor large data frames, it can be useful to view the data in a browser window. To facilitate this, you can define a View() function as follows. This function will save the data frame to a temporary HTML file and open it in your default web browser.\n\nimport tempfile\nimport webbrowser\n\n# Define a simple function to view data frame in a browser window\ndef View(df: pd.DataFrame):\n    html = df.to_html()\n    with tempfile.NamedTemporaryFile('w', \n    delete=False, suffix='.html') as f:\n        url = 'file://' + f.name\n        f.write(html)\n    webbrowser.open(url)\n\n# Call the function\nView(df)"
  },
  {
    "objectID": "docs/usage.html#common-data-transformations",
    "href": "docs/usage.html#common-data-transformations",
    "title": "Suggestions for Usage",
    "section": "Common Data Transformations",
    "text": "Common Data Transformations\nThe International Financial Statistics (IFS) database provides key macroeconomic aggregates that are frequently needed when working with other IMF datasets. Here, we’ll demonstrate how to use three fundamental indicators—GDP, price deflators, and population statistics—to transform your data.\nThese transformations are essential for:\n\nConverting nominal to real dollar values\nCalculating per capita metrics\nHarmonizing data across different frequencies\nAdjusting for different unit scales\n\nFor a complete, end-to-end example of these transformations in a real analysis workflow, see Jenny Xu’s superb demo notebook.\n\nFetching IFS Adjusters\nFirst, let’s retrieve the key adjustment variables from the IFS database:\n\n# Fetch GDP Deflator (Index, Annual)\ndeflator = imfp.imf_dataset(\n    database_id=\"IFS\",\n    indicator=\"NGDP_D_SA_IX\",\n    freq=\"Q\",\n    start_year=2010\n)\n\n# Fetch Population Estimates (Annual)\npopulation = imfp.imf_dataset(\n    database_id=\"IFS\",\n    indicator=\"LP_PE_NUM\",\n    freq=\"A\",\n    start_year=2010\n)\n\n# Fetch Exchange Rate (Annual)\nexchange_rate = imfp.imf_dataset(\n    database_id=\"IFS\", \n    indicator=\"ENDE_XDC_USD_RATE\",\n    freq=\"Q\",\n    # start_year=2010 currently breaks this query for some reason\n)\n\nWe’ll also retireve a nominal GDP series to be adjusted:\n\n# Fetch Nominal GDP (Domestic currency, annual)\nnominal_gdp = imfp.imf_dataset(\n    database_id=\"IFS\", \n    indicator=\"NGDP_XDC\",\n    freq=\"A\",\n    start_year=2010\n)\n\nKey IFS Indicators:\n\nNGDP_D_SA_IX: GDP deflator index (seasonally adjusted)\nLP_PE_NUM: Population estimates\nENDE_XDC_USD_RATE: Exchange rate (domestic currency per USD)\nNGDP_XDC: Nominal GDP in domestic currency\n\n\n\nHarmonizing Frequencies\nWhen working with data of different frequencies, you’ll often need to harmonize them. For example, population and national GDP are available at an annual frequency, while the GDP deflator and exchange rates can only be obtained at a monthly or quarterly frequency. There are two common approaches:\n\nUsing Q4 values: This approach is often used for stock variables (measurements taken at a point in time) and when you want to align with end-of-year values:\n\n\n# Keep only Q4 observations for annual comparisons\ndeflator = deflator[deflator['time_period'].str.contains(\"Q4\")]\nexchange_rate = exchange_rate[exchange_rate['time_period'].str.contains(\"Q4\")]\n\n# Extract just the year from the time period for Q4 data\ndeflator['time_period'] = deflator['time_period'].str[:4]\nexchange_rate['time_period'] = exchange_rate['time_period'].str[:4]\n\n\nCalculating annual averages: This approach is more appropriate for flow variables (measurements over a period) and when you want to smooth out seasonal variations:\n\n\n# Alternative: Calculate annual averages\ndeflator = deflator.groupby(\n    ['ref_area', deflator['time_period']], \n    as_index=False\n).agg({\n    'obs_value': 'mean'\n})\n\nChoose the appropriate method based on your specific analysis needs and the economic meaning of your variables.\n\n\nUnit Multiplier Adjustment\nIMF data often includes a unit_mult column that indicates the scale of the values (e.g., millions, billions). We can write a helper function to apply these scaling factors:\n\ndef apply_unit_multiplier(df):\n    \"\"\"Convert to numeric, adjust values using IMF's scaling factors, and drop\n    missing values\"\"\"\n    df['obs_value'] = pd.to_numeric(df['obs_value'])\n    df['unit_mult'] = pd.to_numeric(df['unit_mult'])\n    df['adjusted_value'] = df['obs_value'] * 10 ** df['unit_mult']\n    df = df.dropna(subset=[\"obs_value\"])\n    return df\n\n# Apply to each dataset\ndeflator = apply_unit_multiplier(deflator)\npopulation = apply_unit_multiplier(population)\nexchange_rate = apply_unit_multiplier(exchange_rate)\nnominal_gdp = apply_unit_multiplier(nominal_gdp)\n\n\n\nMerging Datasets\nAfter harmonizing unit scales, we can combine the datasets using pd.DataFrame.merge() with ref_area and time_period as keys:\n\nmerged = (\n    nominal_gdp.merge(\n        deflator,\n        on=['ref_area', 'time_period'],\n        suffixes=('_gdp', '_deflator')\n    )\n    .merge(\n        population,\n        on=['ref_area', 'time_period']\n    )\n    .merge(\n        exchange_rate,\n        on=['ref_area', 'time_period'],\n        suffixes=('_population', '_exchange_rate')\n    )\n)\n\n\n\nCalculating Real Values\nWith the merged dataset, we can now calculate real GDP and per capita values:\n\n# Convert nominal to real GDP\nmerged['real_gdp'] = (\n    (merged['adjusted_value_gdp'] / merged['adjusted_value_deflator']) * 100\n)\n\n# Calculate per capita values (using population obs_value)\nmerged['real_gdp_per_capita'] = merged['real_gdp'] / merged['adjusted_value_population']\n\n# Display the first 5 rows of the transformed data\nmerged[['time_period', 'real_gdp', 'real_gdp_per_capita']].head()\n\n\n\n\n\n\n\n\ntime_period\nreal_gdp\nreal_gdp_per_capita\n\n\n\n\n0\n2011\n3551364668794.20\n82248.89\n\n\n1\n2012\n3792317490278.53\n85521.44\n\n\n2\n2013\n3967309320845.69\n87155.33\n\n\n3\n2014\n4144699824894.22\n88751.48\n\n\n4\n2015\n4417512779956.08\n92265.37\n\n\n\n\n\n\n\n\n\nExchange Rate Adjustment\nNote that this result is still in the domestic currency of the country. If you need to convert to a common currency, you can use the exchange rate data from the IFS database.\n\n# Because 'adjusted_value_exrate' is local-currency-per-USD,\n# dividing local-currency real GDP by it yields GDP in USD.\nmerged[\"real_gdp_usd\"] = (\n    merged[\"real_gdp\"] / merged[\"adjusted_value_exchange_rate\"]\n)\n\n# (Optional) real GDP per capita in USD\nmerged[\"real_gdp_usd_per_capita\"] = (\n    merged[\"real_gdp_usd\"] / merged[\"adjusted_value_population\"]\n)\n\n# Inspect results\nmerged[[\"time_period\",\"ref_area\",\"real_gdp\",\"real_gdp_usd\",\"real_gdp_usd_per_capita\"]].head()\n\n\n\n\n\n\n\n\ntime_period\nref_area\nreal_gdp\nreal_gdp_usd\nreal_gdp_usd_per_capita\n\n\n\n\n0\n2011\nKE\n3551364668794.20\n41747313843.78\n966.86\n\n\n1\n2012\nKE\n3792317490278.53\n44096304805.05\n994.43\n\n\n2\n2013\nKE\n3967309320845.69\n45965960945.06\n1009.80\n\n\n3\n2014\nKE\n4144699824894.22\n45796944714.40\n980.66\n\n\n4\n2015\nKE\n4417512779956.08\n43177131580.22\n901.81"
  }
]