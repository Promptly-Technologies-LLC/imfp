[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "imfp",
    "section": "",
    "text": "imfp, by Christopher C. Smith, is a Python package for downloading data from the International Monetary Fund’s RESTful JSON API.\n\n\nTo install the stable version of imfp from PyPi, use pip.\npip install -q --upgrade imfp\nTo load the library, use import:\n\nimport imfp\n\n\n\n\n\n\nimfp outputs data in a pandas data frame, so you will want to use the pandas package for its functions for viewing and manipulating this object type. I also recommend matplotlib or seaborn for making plots, and numpy for computation. These packages can be installed using pip and loaded using import:\npip install -q pandas matplotlib seaborn numpy\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n\n\n\n\nThe imfp package introduces four core functions: imfp.imf_databases, imfp.imf_parameters, imfp.imf_parameter_defs, and imfp.imf_dataset. The function for downloading datasets is imfp.imf_dataset, but you will need the other functions to determine what arguments to supply to imfp.imf_dataset. For instance, all calls to imfp.imf_dataset require a database_id. This is because the IMF serves many different databases through its API, and the API needs to know which of these many databases you’re requesting data from. To obtain a list of databases, use imfp.imf_databases, like so:\n\n#Fetch the list of databases available through the IMF API\ndatabases = imfp.imf_databases()\ndatabases.head()\n\n\n\n\n\n\n\n\ndatabase_id\ndescription\n\n\n\n\n0\nBOP_2017M06\nBalance of Payments (BOP), 2017 M06\n\n\n1\nBOP_2020M3\nBalance of Payments (BOP), 2020 M03\n\n\n2\nBOP_2017M11\nBalance of Payments (BOP), 2017 M11\n\n\n3\nDOT_2020Q1\nDirection of Trade Statistics (DOTS), 2020 Q1\n\n\n4\nGFSMAB2016\nGovernment Finance Statistics Yearbook (GFSY 2...\n\n\n\n\n\n\n\nThis function returns the IMF’s listing of 259 databases available through the API. (In reality, 8 of the listed databases are defunct and not actually available: FAS_2015, GFS01, FM202010, APDREO202010, AFRREO202010, WHDREO202010, BOPAGG_2020, DOT_2020Q1.)\nTo view and explore the database list, it’s possible to explore subsets of the data frame by row number with databases.loc:\n\n# View a subset consisting of rows 5 through 9\ndatabases.loc[5:9]\n\n\n\n\n\n\n\n\ndatabase_id\ndescription\n\n\n\n\n5\nBOP_2019M12\nBalance of Payments (BOP), 2019 M12\n\n\n6\nGFSYFALCS2014\nGovernment Finance Statistics Yearbook (GFSY 2...\n\n\n7\nGFSE2016\nGovernment Finance Statistics Yearbook (GFSY 2...\n\n\n8\nFM201510\nFiscal Monitor (FM) October 2015\n\n\n9\nGFSIBS2016\nGovernment Finance Statistics Yearbook (GFSY 2...\n\n\n\n\n\n\n\nOr, if you already know which database you want, you can fetch the corresponding code by searching for a string match using str.contains and subsetting the data frame for matching rows. For instance, here’s how to search for commodities data:\n\ndatabases[databases['description'].str.contains(\"Commodity\")]\n\n\n\n\n\n\n\n\ndatabase_id\ndescription\n\n\n\n\n298\nPCTOT\nCommodity Terms of Trade\n\n\n300\nPCPS\nPrimary Commodity Price System (PCPS)\n\n\n\n\n\n\n\n\n\n\nOnce you have a database_id, it’s possible to make a call to imfp.imf_dataset to fetch the entire database: imfp.imf_dataset(database_id). However, while this will succeed for a few small databases, it will fail for all of the larger ones. And even in the rare case when it succeeds, fetching an entire database can take a long time. You’re much better off supplying additional filter parameters to reduce the size of your request.\nRequests to databases available through the IMF API are complicated by the fact that each database uses a different set of parameters when making a request. (At last count, there were 43 unique parameters used in making API requests from the various databases!) You also have to have the list of valid input codes for each parameter. The imfp.imf_parameters function solves this problem. Use the function to obtain the full list of parameters and valid input codes for a given database:\n\n# Fetch list of valid parameters and input codes for commodity price database\nparams = imfp.imf_parameters(\"PCPS\")\n\nThe imfp.imf_parameters function returns a dictionary of data frames. Each dictionary key name corresponds to a parameter used in making requests from the database:\n\n# Get key names from the params object\nparams.keys()\n\ndict_keys(['freq', 'ref_area', 'commodity', 'unit_measure'])\n\n\nIn the event that a parameter name is not self-explanatory, the imfp.imf_parameter_defs function can be used to fetch short text descriptions of each parameter:\n\n# Fetch and display parameter text descriptions for the commodity price database\nimfp.imf_parameter_defs(\"PCPS\")\n\n\n\n\n\n\n\n\nparameter\ndescription\n\n\n\n\n0\nfreq\nFrequency\n\n\n1\nref_area\nGeographical Areas\n\n\n2\ncommodity\nIndicator\n\n\n3\nunit_measure\nUnit\n\n\n\n\n\n\n\nEach named list item is a data frame containing a vector of valid input codes that can be used with the named parameter, and a vector of text descriptions of what each code represents.\nTo access the data frame containing valid values for each parameter, subset the params dict by the parameter name:\n\n# View the data frame of valid input codes for the frequency parameter\nparams['freq']\n\n\n\n\n\n\n\n\ninput_code\ndescription\n\n\n\n\n0\nA\nAnnual\n\n\n1\nM\nMonthly\n\n\n2\nQ\nQuarterly\n\n\n\n\n\n\n\n\n\n\nNote that pandas data frames in Python can be a little difficult to work with, because Python doesn’t have a built-in variable explorer. If you’re doing data science, I recommend using an IDE like RStudio or Spyder that has a built-in variable explorer. However, if you don’t have a variable explorer, you can prevent Python from truncating data frames using the options in pandas. For instance, to increase the maximum allowed column width to 100 characters, we can use pandas.options.display.max_colwidth = 100.\nAlternatively, it’s possible to open the data frame in a new window to view it in full:\n\nimport imfp\nimport tempfile\nimport webbrowser\n\n# Define a simple function to view data frame in a browser window\ndef View(df):\n    html = df.to_html()\n    with tempfile.NamedTemporaryFile('w', delete=False, suffix='.html') as f:\n        url = 'file://' + f.name\n        f.write(html)\n    webbrowser.open(url)\n\n# Open data frame in a new browser window using the function\ndf = imfp.imf_databases()\nView(df)\n\n\n\n\nThere are two ways to supply parameters to imfp.imf_dataset: by supplying list arguments or by supplying a modified parameters dict. The list arguments workflow will be more intuitive for most users, but the dict argument workflow requires a little less code.\n\n\nTo supply list arguments, just find the codes you want and supply them to imfp.imf_dataset using the parameter name as the argument name. The example below shows how to request 2000–2015 annual coal prices from the Primary Commodity Price System database:\n\n# Fetch the 'freq' input code for annual frequency\nselected_freq = list(\n    params['freq']['input_code'][params['freq']['description'].str.contains(\"Annual\")]\n)\n\n# Fetch the 'commodity' input code for coal\nselected_commodity = list(\n    params['commodity']['input_code'][params['commodity']['description'].str.contains(\"Coal\")]\n)\n\n# Fetch the 'unit_measure' input code for index\nselected_unit_measure = list(\n    params['unit_measure']['input_code'][params['unit_measure']['description'].str.contains(\"Index\")]\n)\n\n# Request data from the API\ndf = imfp.imf_dataset(database_id = \"PCPS\",\n         freq = selected_freq, commodity = selected_commodity,\n         unit_measure = selected_unit_measure,\n         start_year = 2000, end_year = 2015)\n\n# Display the first few entries in the retrieved data frame\ndf.head()\n\n\n\n\n\n\n\n\nfreq\nref_area\ncommodity\nunit_measure\nunit_mult\ntime_format\ntime_period\nobs_value\n\n\n\n\n0\nA\nW00\nPCOAL\nIX\n0\nP1Y\n2000\n39.3510230293202\n\n\n1\nA\nW00\nPCOAL\nIX\n0\nP1Y\n2001\n49.3378587284039\n\n\n2\nA\nW00\nPCOAL\nIX\n0\nP1Y\n2002\n39.4949091648006\n\n\n3\nA\nW00\nPCOAL\nIX\n0\nP1Y\n2003\n43.2878876950788\n\n\n4\nA\nW00\nPCOAL\nIX\n0\nP1Y\n2004\n82.9185858052862\n\n\n\n\n\n\n\n\n\n\nTo supply a list object, modify each data frame in the params list object to retain only the rows you want, and then supply the modified list object to imfp.imf_dataset as its parameters argument. Here is how to make the same request for annual coal price data using a parameters list:\n\n# Fetch the 'freq' input code for annual frequency\nparams['freq'] = params['freq'][params['freq']['description'].str.contains(\"Annual\")]\n\n# Fetch the 'commodity' input code(s) for coal\nparams['commodity'] = params['commodity'][params['commodity']['description'].str.contains(\"Coal\")]\n\n# Fetch the 'unit_measure' input code for index\nparams['unit_measure'] = params['unit_measure'][params['unit_measure']['description'].str.contains(\"Index\")]\n\n# Request data from the API\ndf = imfp.imf_dataset(database_id = \"PCPS\",\n         parameters = params,\n         start_year = 2000, end_year = 2015)\n\n# Display the first few entries in the retrieved data frame\ndf.head()\n\n\n\n\n\n\n\n\nfreq\nref_area\ncommodity\nunit_measure\nunit_mult\ntime_format\ntime_period\nobs_value\n\n\n\n\n0\nA\nW00\nPCOAL\nIX\n0\nP1Y\n2000\n39.3510230293202\n\n\n1\nA\nW00\nPCOAL\nIX\n0\nP1Y\n2001\n49.3378587284039\n\n\n2\nA\nW00\nPCOAL\nIX\n0\nP1Y\n2002\n39.4949091648006\n\n\n3\nA\nW00\nPCOAL\nIX\n0\nP1Y\n2003\n43.2878876950788\n\n\n4\nA\nW00\nPCOAL\nIX\n0\nP1Y\n2004\n82.9185858052862\n\n\n\n\n\n\n\n\n\n\n\n\nNote that all columns in the returned data frame are character vectors, and that to plot the series we will need to convert to valid numeric or date formats. Using seaborn with hue, we can plot different indicators in different colors:\n\n# Convert obs_value to numeric and time_period to integer year\ndf = df.astype({\"time_period\" : int, \"obs_value\" : float})\n\n# Plot prices of different commodities in different colors with seaborn\nsns.lineplot(data=df, x='time_period', y='obs_value', hue='commodity');\n\n\n\n\n\n\n\n\nAlso note that the returned data frame has mysterious-looking codes as values in some columns.\nCodes in the time_format column are ISO 8601 duration codes. In this case, “P1Y” means “periods of 1 year.” The unit_mult column represents the number of zeroes you should add to the value column. For instance, if value is in millions, then the unit multiplier will be 6. If in billions, then the unit multiplier will be 9.\nThe meanings of the other codes are stored in our params object and can be fetched with a join. For instance to fetch the meaning of the ref_area code “W00”, we can perform a left join with the params['ref_area'] data frame and use select to replace ref_area with the parameter description:\n\n# Join df with params['ref_area'] to fetch code description\ndf = df.merge(params['ref_area'], left_on='ref_area',right_on='input_code',how='left')\n\n# Drop redundant columns and rename description column\ndf = df.drop(columns=['ref_area','input_code']).rename(columns={\"description\":\"ref_area\"})\n\n# View first few columns in the modified data frame\ndf.head()\n\n\n\n\n\n\n\n\nfreq\ncommodity\nunit_measure\nunit_mult\ntime_format\ntime_period\nobs_value\nref_area\n\n\n\n\n0\nA\nPCOAL\nIX\n0\nP1Y\n2000\n39.351023\nAll Countries, excluding the IO\n\n\n1\nA\nPCOAL\nIX\n0\nP1Y\n2001\n49.337859\nAll Countries, excluding the IO\n\n\n2\nA\nPCOAL\nIX\n0\nP1Y\n2002\n39.494909\nAll Countries, excluding the IO\n\n\n3\nA\nPCOAL\nIX\n0\nP1Y\n2003\n43.287888\nAll Countries, excluding the IO\n\n\n4\nA\nPCOAL\nIX\n0\nP1Y\n2004\n82.918586\nAll Countries, excluding the IO\n\n\n\n\n\n\n\n\n\n\n\n\nimfp.set_imf_app_name() allows users to set a custom application name to be used when making API calls to the IMF API. The IMF API has an application-based rate limit of 50 requests per second, with the application identified by the “user_agent” variable in the request header.\nThis could prove problematic if the imfp library became too popular and too many users tried to make simultaneous API requests using the default app name. By setting a custom application name, users can avoid hitting rate limits and being blocked by the API. imfp.set_imf_app_name() sets the application name by changing the IMF_APP_NAME variable in the environment. If this variable doesn’t exist, imfp.set_imf_app_name() will create it.\nTo set a custom application name, simply call the imfp.set_imf_app_name() function with your desired application name as an argument:\n\n# Set custom app name as an environment variable\nimfp.set_imf_app_name(\"my_custom_app_name\")\n\nThe function will throw an error if the provided name is missing, NULL, NA, not a string, or longer than 255 characters. If the provided name is “imfr” (the default) or an empty string, the function will issue a warning recommending the use of a unique app name to avoid hitting rate limits.\n\n\n\nBy default, imfp enforces a mandatory 1.5-second wait time between API calls to prevent repeated or recursive calls from exceeding the API’s bandwidth/rate limit. This wait time should be sufficient for most applications. However, if you are running parallel processes using imfp (e.g. during cross-platform testing), this wait time may be insufficient to prevent you from running up against the API’s rate and bandwidth limits. You can change this wait time by calling the set_imf_wait_time function with a numeric value, in seconds. For instance, to enforce a five-second wait time between API calls, use set_imf_wait_time(10).\nAlso note that by default, imfp functions will retry any API call rejected for bandwidth or rate limit reasons. The number of times imfp will attempt the call is set by the times argument, with a default value of 3. (With this value, requests will be retried twice after an initial failure.) Note that imfp enforces an exponentially increasing wait time between function calls, with a base wait time of 5 seconds on the first retry, so it is not recommended to set a high value for times.\n\n\n\n\n\nIf pyproject.toml version has been incremented, automatically deploy Github release from main with release notes auto-generated from News file or PR message\nImplement automatic build/render of readthedocs documentation with Sphinx\nRender/publish Github Pages documentation with Quarto\nAutomatically update all lockfile dependencies\nMove response mocking functionality from _download_parse to _imf_get\nInvestigate and implement different and more appropriate exception types, as we’re currently handling too many different cases with ValueError\nMore fully investigate the types of metadata available through the API and the most appropriate way to return them when a user calls include_metadata\nImplement optional response caching for imf_databases and imf_parameters\nSimplify and modularize some of the code, particularly in imf_dataset\n\n\n\n\nI would love to have your help in improving imfp. If you encounter a bug while using the library, please open an issue. Alternatively, fix the bug and open a pull request to the dev branch. Thanks in advance for your help!\nNote to maintainers: To deploy a new version of the package, increment the version number with poetry version patch (or minor/major for larger updates), update the lock file with the latest dependencies with poetry update, run the tests with pytest tests, make any necessary documentation changes in NEWS and README.ipynb, and push to dev. Github Actions will automatically format the code with black, render the README, and run the unit tests. If the workflow completes successfully, open a PR to main. After merging, the workflow will test again as one last sanity check and then automatically deploy the new version to PyPi. Currently, new Github releases must be created manually, but this will be automated in the future."
  },
  {
    "objectID": "index.html#installation",
    "href": "index.html#installation",
    "title": "imfp",
    "section": "",
    "text": "To install the stable version of imfp from PyPi, use pip.\npip install -q --upgrade imfp\nTo load the library, use import:\n\nimport imfp"
  },
  {
    "objectID": "index.html#usage",
    "href": "index.html#usage",
    "title": "imfp",
    "section": "",
    "text": "imfp outputs data in a pandas data frame, so you will want to use the pandas package for its functions for viewing and manipulating this object type. I also recommend matplotlib or seaborn for making plots, and numpy for computation. These packages can be installed using pip and loaded using import:\npip install -q pandas matplotlib seaborn numpy\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n\n\n\n\nThe imfp package introduces four core functions: imfp.imf_databases, imfp.imf_parameters, imfp.imf_parameter_defs, and imfp.imf_dataset. The function for downloading datasets is imfp.imf_dataset, but you will need the other functions to determine what arguments to supply to imfp.imf_dataset. For instance, all calls to imfp.imf_dataset require a database_id. This is because the IMF serves many different databases through its API, and the API needs to know which of these many databases you’re requesting data from. To obtain a list of databases, use imfp.imf_databases, like so:\n\n#Fetch the list of databases available through the IMF API\ndatabases = imfp.imf_databases()\ndatabases.head()\n\n\n\n\n\n\n\n\ndatabase_id\ndescription\n\n\n\n\n0\nBOP_2017M06\nBalance of Payments (BOP), 2017 M06\n\n\n1\nBOP_2020M3\nBalance of Payments (BOP), 2020 M03\n\n\n2\nBOP_2017M11\nBalance of Payments (BOP), 2017 M11\n\n\n3\nDOT_2020Q1\nDirection of Trade Statistics (DOTS), 2020 Q1\n\n\n4\nGFSMAB2016\nGovernment Finance Statistics Yearbook (GFSY 2...\n\n\n\n\n\n\n\nThis function returns the IMF’s listing of 259 databases available through the API. (In reality, 8 of the listed databases are defunct and not actually available: FAS_2015, GFS01, FM202010, APDREO202010, AFRREO202010, WHDREO202010, BOPAGG_2020, DOT_2020Q1.)\nTo view and explore the database list, it’s possible to explore subsets of the data frame by row number with databases.loc:\n\n# View a subset consisting of rows 5 through 9\ndatabases.loc[5:9]\n\n\n\n\n\n\n\n\ndatabase_id\ndescription\n\n\n\n\n5\nBOP_2019M12\nBalance of Payments (BOP), 2019 M12\n\n\n6\nGFSYFALCS2014\nGovernment Finance Statistics Yearbook (GFSY 2...\n\n\n7\nGFSE2016\nGovernment Finance Statistics Yearbook (GFSY 2...\n\n\n8\nFM201510\nFiscal Monitor (FM) October 2015\n\n\n9\nGFSIBS2016\nGovernment Finance Statistics Yearbook (GFSY 2...\n\n\n\n\n\n\n\nOr, if you already know which database you want, you can fetch the corresponding code by searching for a string match using str.contains and subsetting the data frame for matching rows. For instance, here’s how to search for commodities data:\n\ndatabases[databases['description'].str.contains(\"Commodity\")]\n\n\n\n\n\n\n\n\ndatabase_id\ndescription\n\n\n\n\n298\nPCTOT\nCommodity Terms of Trade\n\n\n300\nPCPS\nPrimary Commodity Price System (PCPS)\n\n\n\n\n\n\n\n\n\n\nOnce you have a database_id, it’s possible to make a call to imfp.imf_dataset to fetch the entire database: imfp.imf_dataset(database_id). However, while this will succeed for a few small databases, it will fail for all of the larger ones. And even in the rare case when it succeeds, fetching an entire database can take a long time. You’re much better off supplying additional filter parameters to reduce the size of your request.\nRequests to databases available through the IMF API are complicated by the fact that each database uses a different set of parameters when making a request. (At last count, there were 43 unique parameters used in making API requests from the various databases!) You also have to have the list of valid input codes for each parameter. The imfp.imf_parameters function solves this problem. Use the function to obtain the full list of parameters and valid input codes for a given database:\n\n# Fetch list of valid parameters and input codes for commodity price database\nparams = imfp.imf_parameters(\"PCPS\")\n\nThe imfp.imf_parameters function returns a dictionary of data frames. Each dictionary key name corresponds to a parameter used in making requests from the database:\n\n# Get key names from the params object\nparams.keys()\n\ndict_keys(['freq', 'ref_area', 'commodity', 'unit_measure'])\n\n\nIn the event that a parameter name is not self-explanatory, the imfp.imf_parameter_defs function can be used to fetch short text descriptions of each parameter:\n\n# Fetch and display parameter text descriptions for the commodity price database\nimfp.imf_parameter_defs(\"PCPS\")\n\n\n\n\n\n\n\n\nparameter\ndescription\n\n\n\n\n0\nfreq\nFrequency\n\n\n1\nref_area\nGeographical Areas\n\n\n2\ncommodity\nIndicator\n\n\n3\nunit_measure\nUnit\n\n\n\n\n\n\n\nEach named list item is a data frame containing a vector of valid input codes that can be used with the named parameter, and a vector of text descriptions of what each code represents.\nTo access the data frame containing valid values for each parameter, subset the params dict by the parameter name:\n\n# View the data frame of valid input codes for the frequency parameter\nparams['freq']\n\n\n\n\n\n\n\n\ninput_code\ndescription\n\n\n\n\n0\nA\nAnnual\n\n\n1\nM\nMonthly\n\n\n2\nQ\nQuarterly\n\n\n\n\n\n\n\n\n\n\nNote that pandas data frames in Python can be a little difficult to work with, because Python doesn’t have a built-in variable explorer. If you’re doing data science, I recommend using an IDE like RStudio or Spyder that has a built-in variable explorer. However, if you don’t have a variable explorer, you can prevent Python from truncating data frames using the options in pandas. For instance, to increase the maximum allowed column width to 100 characters, we can use pandas.options.display.max_colwidth = 100.\nAlternatively, it’s possible to open the data frame in a new window to view it in full:\n\nimport imfp\nimport tempfile\nimport webbrowser\n\n# Define a simple function to view data frame in a browser window\ndef View(df):\n    html = df.to_html()\n    with tempfile.NamedTemporaryFile('w', delete=False, suffix='.html') as f:\n        url = 'file://' + f.name\n        f.write(html)\n    webbrowser.open(url)\n\n# Open data frame in a new browser window using the function\ndf = imfp.imf_databases()\nView(df)\n\n\n\n\nThere are two ways to supply parameters to imfp.imf_dataset: by supplying list arguments or by supplying a modified parameters dict. The list arguments workflow will be more intuitive for most users, but the dict argument workflow requires a little less code.\n\n\nTo supply list arguments, just find the codes you want and supply them to imfp.imf_dataset using the parameter name as the argument name. The example below shows how to request 2000–2015 annual coal prices from the Primary Commodity Price System database:\n\n# Fetch the 'freq' input code for annual frequency\nselected_freq = list(\n    params['freq']['input_code'][params['freq']['description'].str.contains(\"Annual\")]\n)\n\n# Fetch the 'commodity' input code for coal\nselected_commodity = list(\n    params['commodity']['input_code'][params['commodity']['description'].str.contains(\"Coal\")]\n)\n\n# Fetch the 'unit_measure' input code for index\nselected_unit_measure = list(\n    params['unit_measure']['input_code'][params['unit_measure']['description'].str.contains(\"Index\")]\n)\n\n# Request data from the API\ndf = imfp.imf_dataset(database_id = \"PCPS\",\n         freq = selected_freq, commodity = selected_commodity,\n         unit_measure = selected_unit_measure,\n         start_year = 2000, end_year = 2015)\n\n# Display the first few entries in the retrieved data frame\ndf.head()\n\n\n\n\n\n\n\n\nfreq\nref_area\ncommodity\nunit_measure\nunit_mult\ntime_format\ntime_period\nobs_value\n\n\n\n\n0\nA\nW00\nPCOAL\nIX\n0\nP1Y\n2000\n39.3510230293202\n\n\n1\nA\nW00\nPCOAL\nIX\n0\nP1Y\n2001\n49.3378587284039\n\n\n2\nA\nW00\nPCOAL\nIX\n0\nP1Y\n2002\n39.4949091648006\n\n\n3\nA\nW00\nPCOAL\nIX\n0\nP1Y\n2003\n43.2878876950788\n\n\n4\nA\nW00\nPCOAL\nIX\n0\nP1Y\n2004\n82.9185858052862\n\n\n\n\n\n\n\n\n\n\nTo supply a list object, modify each data frame in the params list object to retain only the rows you want, and then supply the modified list object to imfp.imf_dataset as its parameters argument. Here is how to make the same request for annual coal price data using a parameters list:\n\n# Fetch the 'freq' input code for annual frequency\nparams['freq'] = params['freq'][params['freq']['description'].str.contains(\"Annual\")]\n\n# Fetch the 'commodity' input code(s) for coal\nparams['commodity'] = params['commodity'][params['commodity']['description'].str.contains(\"Coal\")]\n\n# Fetch the 'unit_measure' input code for index\nparams['unit_measure'] = params['unit_measure'][params['unit_measure']['description'].str.contains(\"Index\")]\n\n# Request data from the API\ndf = imfp.imf_dataset(database_id = \"PCPS\",\n         parameters = params,\n         start_year = 2000, end_year = 2015)\n\n# Display the first few entries in the retrieved data frame\ndf.head()\n\n\n\n\n\n\n\n\nfreq\nref_area\ncommodity\nunit_measure\nunit_mult\ntime_format\ntime_period\nobs_value\n\n\n\n\n0\nA\nW00\nPCOAL\nIX\n0\nP1Y\n2000\n39.3510230293202\n\n\n1\nA\nW00\nPCOAL\nIX\n0\nP1Y\n2001\n49.3378587284039\n\n\n2\nA\nW00\nPCOAL\nIX\n0\nP1Y\n2002\n39.4949091648006\n\n\n3\nA\nW00\nPCOAL\nIX\n0\nP1Y\n2003\n43.2878876950788\n\n\n4\nA\nW00\nPCOAL\nIX\n0\nP1Y\n2004\n82.9185858052862"
  },
  {
    "objectID": "index.html#working-with-the-returned-data-frame",
    "href": "index.html#working-with-the-returned-data-frame",
    "title": "imfp",
    "section": "",
    "text": "Note that all columns in the returned data frame are character vectors, and that to plot the series we will need to convert to valid numeric or date formats. Using seaborn with hue, we can plot different indicators in different colors:\n\n# Convert obs_value to numeric and time_period to integer year\ndf = df.astype({\"time_period\" : int, \"obs_value\" : float})\n\n# Plot prices of different commodities in different colors with seaborn\nsns.lineplot(data=df, x='time_period', y='obs_value', hue='commodity');\n\n\n\n\n\n\n\n\nAlso note that the returned data frame has mysterious-looking codes as values in some columns.\nCodes in the time_format column are ISO 8601 duration codes. In this case, “P1Y” means “periods of 1 year.” The unit_mult column represents the number of zeroes you should add to the value column. For instance, if value is in millions, then the unit multiplier will be 6. If in billions, then the unit multiplier will be 9.\nThe meanings of the other codes are stored in our params object and can be fetched with a join. For instance to fetch the meaning of the ref_area code “W00”, we can perform a left join with the params['ref_area'] data frame and use select to replace ref_area with the parameter description:\n\n# Join df with params['ref_area'] to fetch code description\ndf = df.merge(params['ref_area'], left_on='ref_area',right_on='input_code',how='left')\n\n# Drop redundant columns and rename description column\ndf = df.drop(columns=['ref_area','input_code']).rename(columns={\"description\":\"ref_area\"})\n\n# View first few columns in the modified data frame\ndf.head()\n\n\n\n\n\n\n\n\nfreq\ncommodity\nunit_measure\nunit_mult\ntime_format\ntime_period\nobs_value\nref_area\n\n\n\n\n0\nA\nPCOAL\nIX\n0\nP1Y\n2000\n39.351023\nAll Countries, excluding the IO\n\n\n1\nA\nPCOAL\nIX\n0\nP1Y\n2001\n49.337859\nAll Countries, excluding the IO\n\n\n2\nA\nPCOAL\nIX\n0\nP1Y\n2002\n39.494909\nAll Countries, excluding the IO\n\n\n3\nA\nPCOAL\nIX\n0\nP1Y\n2003\n43.287888\nAll Countries, excluding the IO\n\n\n4\nA\nPCOAL\nIX\n0\nP1Y\n2004\n82.918586\nAll Countries, excluding the IO"
  },
  {
    "objectID": "index.html#rate-and-bandwidth-limit-management",
    "href": "index.html#rate-and-bandwidth-limit-management",
    "title": "imfp",
    "section": "",
    "text": "imfp.set_imf_app_name() allows users to set a custom application name to be used when making API calls to the IMF API. The IMF API has an application-based rate limit of 50 requests per second, with the application identified by the “user_agent” variable in the request header.\nThis could prove problematic if the imfp library became too popular and too many users tried to make simultaneous API requests using the default app name. By setting a custom application name, users can avoid hitting rate limits and being blocked by the API. imfp.set_imf_app_name() sets the application name by changing the IMF_APP_NAME variable in the environment. If this variable doesn’t exist, imfp.set_imf_app_name() will create it.\nTo set a custom application name, simply call the imfp.set_imf_app_name() function with your desired application name as an argument:\n\n# Set custom app name as an environment variable\nimfp.set_imf_app_name(\"my_custom_app_name\")\n\nThe function will throw an error if the provided name is missing, NULL, NA, not a string, or longer than 255 characters. If the provided name is “imfr” (the default) or an empty string, the function will issue a warning recommending the use of a unique app name to avoid hitting rate limits.\n\n\n\nBy default, imfp enforces a mandatory 1.5-second wait time between API calls to prevent repeated or recursive calls from exceeding the API’s bandwidth/rate limit. This wait time should be sufficient for most applications. However, if you are running parallel processes using imfp (e.g. during cross-platform testing), this wait time may be insufficient to prevent you from running up against the API’s rate and bandwidth limits. You can change this wait time by calling the set_imf_wait_time function with a numeric value, in seconds. For instance, to enforce a five-second wait time between API calls, use set_imf_wait_time(10).\nAlso note that by default, imfp functions will retry any API call rejected for bandwidth or rate limit reasons. The number of times imfp will attempt the call is set by the times argument, with a default value of 3. (With this value, requests will be retried twice after an initial failure.) Note that imfp enforces an exponentially increasing wait time between function calls, with a base wait time of 5 seconds on the first retry, so it is not recommended to set a high value for times."
  },
  {
    "objectID": "index.html#planned-features",
    "href": "index.html#planned-features",
    "title": "imfp",
    "section": "",
    "text": "If pyproject.toml version has been incremented, automatically deploy Github release from main with release notes auto-generated from News file or PR message\nImplement automatic build/render of readthedocs documentation with Sphinx\nRender/publish Github Pages documentation with Quarto\nAutomatically update all lockfile dependencies\nMove response mocking functionality from _download_parse to _imf_get\nInvestigate and implement different and more appropriate exception types, as we’re currently handling too many different cases with ValueError\nMore fully investigate the types of metadata available through the API and the most appropriate way to return them when a user calls include_metadata\nImplement optional response caching for imf_databases and imf_parameters\nSimplify and modularize some of the code, particularly in imf_dataset"
  },
  {
    "objectID": "index.html#contributing",
    "href": "index.html#contributing",
    "title": "imfp",
    "section": "",
    "text": "I would love to have your help in improving imfp. If you encounter a bug while using the library, please open an issue. Alternatively, fix the bug and open a pull request to the dev branch. Thanks in advance for your help!\nNote to maintainers: To deploy a new version of the package, increment the version number with poetry version patch (or minor/major for larger updates), update the lock file with the latest dependencies with poetry update, run the tests with pytest tests, make any necessary documentation changes in NEWS and README.ipynb, and push to dev. Github Actions will automatically format the code with black, render the README, and run the unit tests. If the workflow completes successfully, open a PR to main. After merging, the workflow will test again as one last sanity check and then automatically deploy the new version to PyPi. Currently, new Github releases must be created manually, but this will be automated in the future."
  }
]